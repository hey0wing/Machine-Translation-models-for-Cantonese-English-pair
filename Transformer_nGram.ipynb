{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Transformer model for language understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu2cV7D4kBFi"
   },
   "source": [
    "FYP: Machine translation models for Cantonese­English pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFG0NDRu5mYQ",
    "outputId": "10b72e31-4689-4efc-9406-9dac3da5c01e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 / unknown移動         1 個檔案。\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tfds-nightly\n",
    "\n",
    "# Pin matplotlib version to 3.2.2 since in the latest version\n",
    "# transformer.ipynb fails with the following error:\n",
    "# https://stackoverflow.com/questions/62953704/valueerror-the-number-of-fixedlocator-locations-5-usually-from-a-call-to-set\n",
    "!pip install -q matplotlib==3.2.2\n",
    "# Chinese font in matplotlib\n",
    "from matplotlib.font_manager import FontProperties\n",
    "!pip install -q wget\n",
    "import wget\n",
    "# !wget -qO taipei_sans_tc_beta.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n",
    "# !mv taipei_sans_tc_beta.ttf /usr/local/lib/python3.6/dist-packages/matplotlib//mpl-data/fonts/ttf\n",
    "# chinese = FontProperties(fname=r'/usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf/taipei_sans_tc_beta.ttf')\n",
    "wget.download('https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download', 'taipei_sans_tc_beta.ttf')\n",
    "!move taipei_sans_tc_beta.ttf c:\\users\\hey0\\anaconda3\\lib\\site-packages/matplotlib//mpl-data/fonts/ttf\n",
    "chinese = FontProperties(fname=r'c:\\users\\hey0\\anaconda3\\lib\\site-packages/matplotlib//mpl-data/fonts/ttf/taipei_sans_tc_beta.ttf')\n",
    "\n",
    "!pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd1NWMxjfsDd"
   },
   "source": [
    "## Setup input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "QWviV8YdYh-C",
    "outputId": "6e3bf9d5-5632-4d95-a958-b4196327e03c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yue</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>大家 好 我 叫 Frank</td>\n",
       "      <td>Hi my name is Frank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>我 收集 人哋 嘅 秘密</td>\n",
       "      <td>and I collect secrets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>而 一切 都 源於 我</td>\n",
       "      <td>It all started with a crazy idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004 年 11 月 一個 瘋狂 嘅 諗法</td>\n",
       "      <td>in November of 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我 當時 打印 咗 三千 張</td>\n",
       "      <td>I printed up 3 000 self addressed postcards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      yue                                          eng\n",
       "0          大家 好 我 叫 Frank                          Hi my name is Frank\n",
       "1            我 收集 人哋 嘅 秘密                        and I collect secrets\n",
       "2             而 一切 都 源於 我             It all started with a crazy idea\n",
       "3  2004 年 11 月 一個 瘋狂 嘅 諗法                          in November of 2004\n",
       "4          我 當時 打印 咗 三千 張  I printed up 3 000 self addressed postcards"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "all_csv = glob.glob(os.getcwd() + \"/Preprocessed_Corpus.csv\")  \n",
    " \n",
    "df_from_each_file = (pd.read_csv(f, sep='\\t', encoding='utf-8') for f in all_csv)\n",
    "df = pd.concat(df_from_each_file)\n",
    "\n",
    "# Check for null\n",
    "df[df['yue'].isnull()]\n",
    "df = df.dropna()\n",
    "\n",
    "YueChar = False\n",
    "# Delete spaces between n-gram in Cantonese\n",
    "# Perform Character based tokenization in Cantonese\n",
    "if YueChar:\n",
    "    df['yue'] = df['yue'].str.replace(r' ', '')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEsv-c0qqLQd"
   },
   "source": [
    "### Set translational direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0r4EQ67kqKcU"
   },
   "outputs": [],
   "source": [
    "inp_lang = 'eng'\n",
    "tar_lang = 'yue'\n",
    "inp = df[inp_lang]\n",
    "tar = df[tar_lang]\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inp.values, tar.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmVWHYyd18kb"
   },
   "source": [
    "## Split dataset into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UudB9uidSkP",
    "outputId": "b327f1e3-5143-4b79-f204-3d55bed31d2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 7848\n",
      "Test size: 1963\n",
      "\n",
      "Total size: 9811\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE = len(list(dataset))\n",
    "train_size = int(0.8 * DATASET_SIZE)\n",
    "test_size = int(0.2 * DATASET_SIZE)\n",
    "\n",
    "dataset = dataset.shuffle(DATASET_SIZE)\n",
    "train_examples = dataset.take(train_size)\n",
    "test_examples = dataset.skip(train_size)\n",
    "# test_examples = remaining.take(test_size)\n",
    "# val_examples = remaining.skip(test_size)\n",
    "\n",
    "print('Train size:', len(list(train_examples)))\n",
    "print('Test size:', len(list(test_examples)))\n",
    "# print('Validation size:', len(list(val_examples)))\n",
    "print()\n",
    "print('Total size:', DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5PlJ-TwK6Oi",
    "outputId": "79fdafc4-e9d3-44f5-f231-e059bc58bf09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'in West Africa', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe4\\xbd\\x8d\\xe6\\x96\\xbc \\xe8\\xa5\\xbf\\xe9\\x9d\\x9e \\xe5\\x98\\x85 \\xe7\\xb4\\xb0 \\xe4\\xbd\\x86 \\xe7\\xbe\\x8e\\xe9\\xba\\x97 \\xe5\\x98\\x85 \\xe5\\x9c\\x8b\\xe5\\xae\\xb6', shape=(), dtype=string)\n",
      "----------\n",
      "tf.Tensor(b'are related to a mental illness', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe9\\x83\\xbd \\xe4\\xbf\\x82 \\xe5\\x90\\x8c \\xe7\\xb2\\xbe\\xe7\\xa5\\x9e\\xe7\\x97\\x85 \\xe6\\x9c\\x89\\xe9\\x97\\x9c', shape=(), dtype=string)\n",
      "----------\n",
      "tf.Tensor(b'the photos most of them are still there', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe5\\x97\\xb0\\xe5\\x95\\xb2 \\xe7\\x9b\\xb8 \\xe5\\xa4\\xa7\\xe5\\xa4\\x9a\\xe6\\x95\\xb8 \\xe4\\xbb\\xb2 \\xe7\\xb9\\xab \\xe5\\x88\\xb0', shape=(), dtype=string)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for inp, tar in train_examples.take(3):\n",
    "  print(inp)\n",
    "  print(tar)\n",
    "  print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "waK4jpjpw2dZ",
    "outputId": "9146e9e0-0437-4f39-a30a-02c9df423afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but it cut down on the variety of food we ate as well\n",
      "但 亦 會 減少 左 我哋 食 嘅 食物 嘅 種類\n",
      "----------\n",
      "didn t prevent Chinese social media from becoming a really public sphere\n",
      "都 阻止 唔到 中國 社交 網絡\n",
      "----------\n",
      "And throughout the book\n",
      "在 本 書 中\n",
      "----------\n",
      "And while I m okay now\n",
      "就算 我 現在 已經 康復 了\n",
      "----------\n",
      "I didn t really exist\n",
      "我 唔 存在\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "sample_examples = []\n",
    "num_samples = 5\n",
    "\n",
    "for inp_t, tar_t in train_examples.take(num_samples):\n",
    "  inp = inp_t.numpy().decode(\"utf-8\")\n",
    "  tar = tar_t.numpy().decode(\"utf-8\")\n",
    "  \n",
    "  print(inp)\n",
    "  print(tar)\n",
    "  print('-' * 10)\n",
    "  \n",
    "  sample_examples.append((inp, tar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCEKotqosGfq"
   },
   "source": [
    "Create a custom subwords tokenizer from the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inp_lang == 'yue':\n",
    "    if YueChar:\n",
    "      input_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "          (inp.numpy() for inp, tar in train_examples), target_vocab_size=2**13, max_subword_length=1)\n",
    "    else:\n",
    "      input_tokenizer = tfds.deprecated.text.TokenTextEncoder(\n",
    "          ' '.join(inp.numpy().decode(\"utf-8\") for inp, tar in train_examples).split(' ')) \n",
    "    target_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "        (tar.numpy() for inp, tar in train_examples), target_vocab_size=2**13)\n",
    "else:\n",
    "    if YueChar:\n",
    "      target_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "          (tar.numpy() for inp, tar in train_examples), target_vocab_size=2**13, max_subword_length=1)\n",
    "    else:\n",
    "      target_tokenizer = tfds.deprecated.text.TokenTextEncoder(\n",
    "          ' '.join(tar.numpy().decode(\"utf-8\") for inp, tar in train_examples).split(' '))\n",
    "    input_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "      (inp.numpy() for inp, tar in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-PPeXeT4WHN"
   },
   "source": [
    "Check the tokenizers with sample string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DYWukNFkGQN",
    "outputId": "902864c3-fa59-45c0-e8f9-17536d62fea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [47, 12, 1038, 148, 20, 1, 5513, 4, 211, 13, 480, 32, 564]\n",
      "The original string: but it cut down on the variety of food we ate as well\n",
      "Tokenized string is [129464, 129140, 129495, 129106, 121682, 129378, 129110, 129505, 129107, 129505, 125765]\n",
      "The original string: 但 亦 會 減少 左 我哋 食 嘅 食物 嘅 種類\n"
     ]
    }
   ],
   "source": [
    "# We can use string in dataset\n",
    "sample_inp = sample_examples[0][0]\n",
    "sample_tar = sample_examples[0][1]\n",
    "\n",
    "tokenized_inp = input_tokenizer.encode(sample_inp)\n",
    "print ('Tokenized string is {}'.format(tokenized_inp))\n",
    "\n",
    "original_inp = input_tokenizer.decode(tokenized_inp)\n",
    "print ('The original string: {}'.format(original_inp))\n",
    "\n",
    "tokenized_tar = target_tokenizer.encode(sample_tar)\n",
    "print ('Tokenized string is {}'.format(tokenized_tar))\n",
    "\n",
    "original_tar = target_tokenizer.decode(tokenized_tar)\n",
    "print ('The original string: {}'.format(original_tar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9KJWJjrsZ4Y"
   },
   "source": [
    "The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf2ntBxjkqK6",
    "outputId": "0234d439-6ab8-45ac-9591-71051d640c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 ----> but \n",
      "12 ----> it \n",
      "1038 ----> cut \n",
      "148 ----> down \n",
      "20 ----> on \n",
      "1 ----> the \n",
      "5513 ----> variety \n",
      "4 ----> of \n",
      "211 ----> food \n",
      "13 ----> we \n",
      "480 ----> ate \n",
      "32 ----> as \n",
      "564 ----> well\n",
      "\n",
      "129464 ----> 但\n",
      "129140 ----> 亦\n",
      "129495 ----> 會\n",
      "129106 ----> 減少\n",
      "121682 ----> 左\n",
      "129378 ----> 我哋\n",
      "129110 ----> 食\n",
      "129505 ----> 嘅\n",
      "129107 ----> 食物\n",
      "129505 ----> 嘅\n",
      "125765 ----> 種類\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_inp:\n",
    "  print ('{} ----> {}'.format(ts, input_tokenizer.decode([ts])))\n",
    "print()\n",
    "for ts in tokenized_tar:\n",
    "  print ('{} ----> {}'.format(ts, target_tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGi4PoVakxdc"
   },
   "source": [
    "Add a start and end token to the input and target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UZwnPr4R055s"
   },
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  lang1 = [input_tokenizer.vocab_size] + input_tokenizer.encode(\n",
    "      lang1.numpy()) + [input_tokenizer.vocab_size+1]\n",
    "\n",
    "  lang2 = [target_tokenizer.vocab_size] + target_tokenizer.encode(\n",
    "      lang2.numpy()) + [target_tokenizer.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tx1sFbR-9fRs"
   },
   "source": [
    "You want to use `Dataset.map` to apply this function to each element of the dataset.  `Dataset.map` runs in graph mode.\n",
    "\n",
    "* Graph tensors do not have a value. \n",
    "* In graph mode you can only use TensorFlow Ops and functions. \n",
    "\n",
    "So you can't `.map` this function directly: You need to wrap it in a `tf.py_function`. The `tf.py_function` will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Mah1cS-P70Iz"
   },
   "outputs": [],
   "source": [
    "def tf_encode(inp, tar):\n",
    "  result_inp, result_tar = tf.py_function(encode, [inp, tar], [tf.int64, tf.int64])\n",
    "  result_inp.set_shape([None])\n",
    "  result_tar.set_shape([None])\n",
    "\n",
    "  return result_inp, result_tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JrGp5Gek6Ql"
   },
   "source": [
    "Note: To keep this example small and relatively fast, drop examples with a length of over 100 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "c081xPGv1CPI"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mk9AZdZ5bcS",
    "outputId": "28e59114-d36d-48c8-bf9d-cef2b24049c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 6863\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "num_examples = 0\n",
    "for inp_indices, tar_indices in train_dataset:\n",
    "  num_examples += 1\n",
    "print(f\"Training size: {num_examples}\")\n",
    "\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RgYUtEECc-Q",
    "outputId": "949dd9c4-d890-4991-f1c7-bebcb9e9c6c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[7772   26   58 ...    0    0    0]\n",
      " [7772   93   11 ...    0    0    0]\n",
      " [7772  110 5302 ...    0    0    0]\n",
      " ...\n",
      " [7772  195   46 ...    0    0    0]\n",
      " [7772    4 2968 ...    0    0    0]\n",
      " [7772   47    6 ...    0    0    0]], shape=(64, 32), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[129531 128819 129396 ...      0      0      0]\n",
      " [129531 127821 126771 ...      0      0      0]\n",
      " [129531  83471 129456 ...      0      0      0]\n",
      " ...\n",
      " [129531 129435 129518 ...      0      0      0]\n",
      " [129531 128834  56231 ...      0      0      0]\n",
      " [129531 129432 129518 ...      0      0      0]], shape=(64, 28), dtype=int64)\n",
      "\n",
      "All string are less than 40 tokens\n",
      "Total batches: 108\n"
     ]
    }
   ],
   "source": [
    "# Check with train set\n",
    "inp_indices, tar_indices  = next(iter(train_dataset))\n",
    "print(inp_indices)\n",
    "print(tar_indices)\n",
    "\n",
    "num_examples = 0\n",
    "for inp_indices, tar_indices in train_dataset:\n",
    "  # cond1 = len(inp_indices) <= MAX_LENGTH\n",
    "  # cond2 = len(tar_indices) <= MAX_LENGTH\n",
    "  # assert cond1 and cond2\n",
    "  num_examples += 1\n",
    "\n",
    "print(f\"\\nAll string are less than {MAX_LENGTH} tokens\")\n",
    "print(f\"Total batches: {num_examples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "## Positional encoding\n",
    "\n",
    "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n",
    "\n",
    "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
    "\n",
    "See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "1kLCla68EloE",
    "outputId": "4595b67d-9fc7-45a2-8678-fbe51c8d8e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s42Uydjkv0hF"
   },
   "source": [
    "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7BYeBCNvi7n",
    "outputId": "2f526483-7e23-49b8-b05e-d76a9c3d654a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0hzukDBgVom"
   },
   "source": [
    "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
    "\n",
    "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxKGuXxaBeeE",
    "outputId": "afa5b144-c85f-4626-e942-12d24586fc9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsxEE_-Wa1gF"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "The attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. \n",
    "\n",
    "For example, consider that `Q` and `K` have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of `dk`. Hence, *square root of `dk`* is used for scaling (and not any other number) because the matmul of `Q` and `K` should have a mean of 0 and variance of 1, and you get a gentler softmax.\n",
    "\n",
    "The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiqETnhCkoXh"
   },
   "source": [
    "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
    "\n",
    "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "n90YjClyInFy"
   },
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAzUAf2DPlNt",
    "outputId": "4f614ff2-a52f-4c81-f5d2-f35876de949d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zg6k-fGhgXra",
    "outputId": "82585d6b-4d8c-411b-c868-7b6343409b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UAq3YOzUgXhb",
    "outputId": "c38b7220-1ced-4987-e510-f34c4f12fe69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOz-4_XIhaTP"
   },
   "source": [
    "Pass all the queries together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dlU8Tm-hYrF",
    "outputId": "4f80eeaf-12c1-4819-ad59-d39bcab1bb2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz5BMC8Kaoqo"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
    "\n",
    "\n",
    "Multi-head attention consists of four parts:\n",
    "*    Linear layers and split into heads.\n",
    "*    Scaled dot-product attention.\n",
    "*    Concatenation of heads.\n",
    "*    Final linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPmbr6F1C-v_"
   },
   "source": [
    "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads. \n",
    "\n",
    "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
    "\n",
    "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D8FJue5lDyZ"
   },
   "source": [
    "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hu94p-_-2_BX",
    "outputId": "8f890a1d-970e-40d3-ee5d-15d4fa4ac349"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBqzJXGfHK3X"
   },
   "source": [
    "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mytb1lPyOHLB",
    "outputId": "b9ba0e9b-1dd9-47b2-be13-3ec500cc6d57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yScbC0MUH8dS"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfYJG-Kvgwy2"
   },
   "source": [
    "The transformer model follows the same general pattern as a standard [sequence to sequence with attention model](nmt_with_attention.ipynb). \n",
    "\n",
    "* The input sentence is passed through `N` encoder layers that generates an output for each word/token in the sequence.\n",
    "* The decoder attends on the encoder's output and its own input (self-attention) to predict the next word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### Encoder layer\n",
    "\n",
    "Each encoder layer consists of sublayers:\n",
    "\n",
    "1.   Multi-head attention (with padding mask) \n",
    "2.    Point wise feed forward networks. \n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
    "\n",
    "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzZRXdO0mI48",
    "outputId": "f782e377-bc21-4e2b-9088-32b8538f85c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### Decoder layer\n",
    "\n",
    "Each decoder layer consists of sublayers:\n",
    "\n",
    "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
    "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
    "3.   Point wise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
    "\n",
    "There are N decoder layers in the transformer.\n",
    "\n",
    "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne2Bqx8k71l0",
    "outputId": "53c7b26c-e654-4dc6-ef3b-613bff14234e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### Encoder\n",
    "\n",
    "The `Encoder` consists of:\n",
    "1.   Input Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers\n",
    "\n",
    "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QG9nueFQKXx",
    "outputId": "c1c5cc6b-19bb-4190-c8d7-f605fb303c07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    " The `Decoder` consists of:\n",
    "1.   Output Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N decoder layers\n",
    "\n",
    "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1jXoAMRZyvu",
    "outputId": "49e16979-6f48-4c6c-c307-0b95259d725e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## Create the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJ4fbQcIkHW1",
    "outputId": "6bc6155a-02f0-44ff-b04d-5ab4b4c387cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
    "\n",
    "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
    "\n",
    "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = input_tokenizer.vocab_size + 2\n",
    "target_vocab_size = target_tokenizer.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "f33ZCgvHpPdG",
    "outputId": "d32a1d68-c675-424d-ddc5-855608622ba6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
    "\n",
    "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next. \n",
    "\n",
    "During training this example uses teacher-forcing (like in the [text generation tutorial](./text_generation.ipynb)). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the transformer predicts each word, *self-attention* allows it to look at the previous words in the input sequence to better predict the next word.\n",
    "\n",
    "To prevent the model from peeking at the expected output the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = f\"{num_layers}layers_{d_model}d_{num_heads}heads_{dff}dff_{EPOCHS}EPOCHS_{YueChar}YueChar\"\n",
    "log_dir = os.path.join(os.path.join(os.getcwd(), 'log'), run_id)\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbvmaKNiznHZ",
    "outputId": "f6bc5b1f-c9b6-4cb7-839f-70abab2c8905",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 11.7638 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 11.7355 Accuracy 0.0208\n",
      "Epoch 1 Batch 100 Loss 11.6604 Accuracy 0.0327\n",
      "Epoch 1 Loss 11.6453 Accuracy 0.0340\n",
      "Time taken for 1 epoch: 607.9599750041962 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 11.3920 Accuracy 0.0357\n",
      "Epoch 2 Batch 50 Loss 11.1756 Accuracy 0.0464\n",
      "Epoch 2 Batch 100 Loss 10.9185 Accuracy 0.0457\n",
      "Epoch 2 Loss 10.8786 Accuracy 0.0461\n",
      "Time taken for 1 epoch: 497.9251027107239 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 10.2482 Accuracy 0.0345\n",
      "Epoch 3 Batch 50 Loss 9.8834 Accuracy 0.0462\n",
      "Epoch 3 Batch 100 Loss 9.5062 Accuracy 0.0447\n",
      "Epoch 3 Loss 9.4529 Accuracy 0.0452\n",
      "Time taken for 1 epoch: 505.4895794391632 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 8.5578 Accuracy 0.0714\n",
      "Epoch 4 Batch 50 Loss 8.2550 Accuracy 0.0437\n",
      "Epoch 4 Batch 100 Loss 7.9260 Accuracy 0.0443\n",
      "Epoch 4 Loss 7.8810 Accuracy 0.0446\n",
      "Time taken for 1 epoch: 529.4213783740997 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 7.1431 Accuracy 0.0286\n",
      "Epoch 5 Batch 50 Loss 7.0540 Accuracy 0.0439\n",
      "Epoch 5 Batch 100 Loss 6.9155 Accuracy 0.0444\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-1\n",
      "Epoch 5 Loss 6.8972 Accuracy 0.0451\n",
      "Time taken for 1 epoch: 526.9308762550354 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 6.6163 Accuracy 0.0286\n",
      "Epoch 6 Batch 50 Loss 6.6746 Accuracy 0.0450\n",
      "Epoch 6 Batch 100 Loss 6.6354 Accuracy 0.0451\n",
      "Epoch 6 Loss 6.6287 Accuracy 0.0454\n",
      "Time taken for 1 epoch: 521.8387689590454 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 6.5581 Accuracy 0.0345\n",
      "Epoch 7 Batch 50 Loss 6.5316 Accuracy 0.0473\n",
      "Epoch 7 Batch 100 Loss 6.4787 Accuracy 0.0510\n",
      "Epoch 7 Loss 6.4710 Accuracy 0.0512\n",
      "Time taken for 1 epoch: 576.5491771697998 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 6.3626 Accuracy 0.0488\n",
      "Epoch 8 Batch 50 Loss 6.3529 Accuracy 0.0568\n",
      "Epoch 8 Batch 100 Loss 6.3074 Accuracy 0.0559\n",
      "Epoch 8 Loss 6.2977 Accuracy 0.0567\n",
      "Time taken for 1 epoch: 620.5645995140076 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 6.0931 Accuracy 0.0405\n",
      "Epoch 9 Batch 50 Loss 6.1922 Accuracy 0.0576\n",
      "Epoch 9 Batch 100 Loss 6.1431 Accuracy 0.0594\n",
      "Epoch 9 Loss 6.1347 Accuracy 0.0595\n",
      "Time taken for 1 epoch: 619.4480321407318 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 6.2370 Accuracy 0.0487\n",
      "Epoch 10 Batch 50 Loss 6.0481 Accuracy 0.0632\n",
      "Epoch 10 Batch 100 Loss 6.0001 Accuracy 0.0625\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train\\ckpt-2\n",
      "Epoch 10 Loss 5.9920 Accuracy 0.0636\n",
      "Time taken for 1 epoch: 590.2319867610931 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 5.7962 Accuracy 0.1004\n",
      "Epoch 11 Batch 50 Loss 5.9151 Accuracy 0.0668\n",
      "Epoch 11 Batch 100 Loss 5.8597 Accuracy 0.0678\n",
      "Epoch 11 Loss 5.8509 Accuracy 0.0682\n",
      "Time taken for 1 epoch: 589.4610123634338 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 5.8040 Accuracy 0.0442\n",
      "Epoch 12 Batch 50 Loss 5.7661 Accuracy 0.0675\n",
      "Epoch 12 Batch 100 Loss 5.7218 Accuracy 0.0701\n",
      "Epoch 12 Loss 5.7115 Accuracy 0.0709\n",
      "Time taken for 1 epoch: 555.0231366157532 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 5.4749 Accuracy 0.1419\n",
      "Epoch 13 Batch 50 Loss 5.6304 Accuracy 0.0688\n",
      "Epoch 13 Batch 100 Loss 5.5732 Accuracy 0.0708\n",
      "Epoch 13 Loss 5.5664 Accuracy 0.0711\n",
      "Time taken for 1 epoch: 606.3662717342377 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 5.3286 Accuracy 0.1315\n",
      "Epoch 14 Batch 50 Loss 5.4792 Accuracy 0.0715\n",
      "Epoch 14 Batch 100 Loss 5.4331 Accuracy 0.0740\n",
      "Epoch 14 Loss 5.4269 Accuracy 0.0746\n",
      "Time taken for 1 epoch: 585.2805936336517 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 5.4843 Accuracy 0.1130\n",
      "Epoch 15 Batch 50 Loss 5.3368 Accuracy 0.0747\n",
      "Epoch 15 Batch 100 Loss 5.2854 Accuracy 0.0739\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train\\ckpt-3\n",
      "Epoch 15 Loss 5.2796 Accuracy 0.0746\n",
      "Time taken for 1 epoch: 558.4588186740875 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 5.2181 Accuracy 0.0598\n",
      "Epoch 16 Batch 50 Loss 5.1844 Accuracy 0.0741\n",
      "Epoch 16 Batch 100 Loss 5.1445 Accuracy 0.0760\n",
      "Epoch 16 Loss 5.1347 Accuracy 0.0771\n",
      "Time taken for 1 epoch: 565.014642238617 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 5.0655 Accuracy 0.0576\n",
      "Epoch 17 Batch 50 Loss 5.0394 Accuracy 0.0817\n",
      "Epoch 17 Batch 100 Loss 4.9970 Accuracy 0.0809\n",
      "Epoch 17 Loss 4.9850 Accuracy 0.0817\n",
      "Time taken for 1 epoch: 530.9024279117584 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 4.8610 Accuracy 0.0567\n",
      "Epoch 18 Batch 50 Loss 4.8795 Accuracy 0.0800\n",
      "Epoch 18 Batch 100 Loss 4.8341 Accuracy 0.0829\n",
      "Epoch 18 Loss 4.8264 Accuracy 0.0837\n",
      "Time taken for 1 epoch: 534.4530844688416 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 4.8388 Accuracy 0.0594\n",
      "Epoch 19 Batch 50 Loss 4.7245 Accuracy 0.0839\n",
      "Epoch 19 Batch 100 Loss 4.6755 Accuracy 0.0860\n",
      "Epoch 19 Loss 4.6649 Accuracy 0.0872\n",
      "Time taken for 1 epoch: 539.0073282718658 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 4.8067 Accuracy 0.0577\n",
      "Epoch 20 Batch 50 Loss 4.5511 Accuracy 0.0857\n",
      "Epoch 20 Batch 100 Loss 4.5105 Accuracy 0.0867\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train\\ckpt-4\n",
      "Epoch 20 Loss 4.4986 Accuracy 0.0880\n",
      "Time taken for 1 epoch: 577.9298868179321 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 4.4205 Accuracy 0.0567\n",
      "Epoch 21 Batch 50 Loss 4.3951 Accuracy 0.0877\n",
      "Epoch 21 Batch 100 Loss 4.3381 Accuracy 0.0901\n",
      "Epoch 21 Loss 4.3255 Accuracy 0.0921\n",
      "Time taken for 1 epoch: 631.7732543945312 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 4.3357 Accuracy 0.0711\n",
      "Epoch 22 Batch 50 Loss 4.2031 Accuracy 0.0945\n",
      "Epoch 22 Batch 100 Loss 4.1536 Accuracy 0.0961\n",
      "Epoch 22 Loss 4.1436 Accuracy 0.0968\n",
      "Time taken for 1 epoch: 548.1924495697021 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 4.0387 Accuracy 0.0710\n",
      "Epoch 23 Batch 50 Loss 4.0217 Accuracy 0.1007\n",
      "Epoch 23 Batch 100 Loss 3.9722 Accuracy 0.1009\n",
      "Epoch 23 Loss 3.9607 Accuracy 0.1023\n",
      "Time taken for 1 epoch: 556.2723824977875 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 3.8722 Accuracy 0.1797\n",
      "Epoch 24 Batch 50 Loss 3.8193 Accuracy 0.1068\n",
      "Epoch 24 Batch 100 Loss 3.7601 Accuracy 0.1067\n",
      "Epoch 24 Loss 3.7480 Accuracy 0.1083\n",
      "Time taken for 1 epoch: 573.5615692138672 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 3.7075 Accuracy 0.0835\n",
      "Epoch 25 Batch 50 Loss 3.6196 Accuracy 0.1153\n",
      "Epoch 25 Batch 100 Loss 3.5736 Accuracy 0.1141\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/train\\ckpt-5\n",
      "Epoch 25 Loss 3.5660 Accuracy 0.1148\n",
      "Time taken for 1 epoch: 601.9008932113647 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 3.5323 Accuracy 0.0911\n",
      "Epoch 26 Batch 50 Loss 3.4297 Accuracy 0.1223\n",
      "Epoch 26 Batch 100 Loss 3.3733 Accuracy 0.1233\n",
      "Epoch 26 Loss 3.3585 Accuracy 0.1243\n",
      "Time taken for 1 epoch: 553.695335149765 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 3.3507 Accuracy 0.1935\n",
      "Epoch 27 Batch 50 Loss 3.1929 Accuracy 0.1277\n",
      "Epoch 27 Batch 100 Loss 3.1438 Accuracy 0.1304\n",
      "Epoch 27 Loss 3.1349 Accuracy 0.1327\n",
      "Time taken for 1 epoch: 594.1223700046539 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 3.1324 Accuracy 0.0903\n",
      "Epoch 28 Batch 50 Loss 2.9987 Accuracy 0.1403\n",
      "Epoch 28 Batch 100 Loss 2.9290 Accuracy 0.1430\n",
      "Epoch 28 Loss 2.9142 Accuracy 0.1451\n",
      "Time taken for 1 epoch: 578.6816556453705 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 2.9360 Accuracy 0.0893\n",
      "Epoch 29 Batch 50 Loss 2.7672 Accuracy 0.1497\n",
      "Epoch 29 Batch 100 Loss 2.7097 Accuracy 0.1520\n",
      "Epoch 29 Loss 2.6997 Accuracy 0.1546\n",
      "Time taken for 1 epoch: 617.6149990558624 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 2.5145 Accuracy 0.2560\n",
      "Epoch 30 Batch 50 Loss 2.5561 Accuracy 0.1620\n",
      "Epoch 30 Batch 100 Loss 2.4893 Accuracy 0.1672\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/train\\ckpt-6\n",
      "Epoch 30 Loss 2.4796 Accuracy 0.1689\n",
      "Time taken for 1 epoch: 623.7210845947266 secs\n",
      "\n",
      "Epoch 31 Batch 0 Loss 2.4048 Accuracy 0.1859\n",
      "Epoch 31 Batch 50 Loss 2.3493 Accuracy 0.1739\n",
      "Epoch 31 Batch 100 Loss 2.2925 Accuracy 0.1754\n",
      "Epoch 31 Loss 2.2825 Accuracy 0.1765\n",
      "Time taken for 1 epoch: 534.4821918010712 secs\n",
      "\n",
      "Epoch 32 Batch 0 Loss 2.3588 Accuracy 0.2800\n",
      "Epoch 32 Batch 50 Loss 2.1529 Accuracy 0.1836\n",
      "Epoch 32 Batch 100 Loss 2.0909 Accuracy 0.1851\n",
      "Epoch 32 Loss 2.0785 Accuracy 0.1883\n",
      "Time taken for 1 epoch: 558.1701424121857 secs\n",
      "\n",
      "Epoch 33 Batch 0 Loss 2.1955 Accuracy 0.1612\n",
      "Epoch 33 Batch 50 Loss 1.9761 Accuracy 0.1881\n",
      "Epoch 33 Batch 100 Loss 1.9196 Accuracy 0.1922\n",
      "Epoch 33 Loss 1.9133 Accuracy 0.1936\n",
      "Time taken for 1 epoch: 578.9211046695709 secs\n",
      "\n",
      "Epoch 34 Batch 0 Loss 2.0475 Accuracy 0.1373\n",
      "Epoch 34 Batch 50 Loss 1.8121 Accuracy 0.1896\n",
      "Epoch 34 Batch 100 Loss 1.7673 Accuracy 0.2005\n",
      "Epoch 34 Loss 1.7607 Accuracy 0.2025\n",
      "Time taken for 1 epoch: 506.9432203769684 secs\n",
      "\n",
      "Epoch 35 Batch 0 Loss 1.7360 Accuracy 0.1806\n",
      "Epoch 35 Batch 50 Loss 1.6586 Accuracy 0.2048\n",
      "Epoch 35 Batch 100 Loss 1.6259 Accuracy 0.2089\n",
      "Saving checkpoint for epoch 35 at ./checkpoints/train\\ckpt-7\n",
      "Epoch 35 Loss 1.6197 Accuracy 0.2118\n",
      "Time taken for 1 epoch: 414.906888961792 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 0 Loss 1.6118 Accuracy 0.2231\n",
      "Epoch 36 Batch 50 Loss 1.5323 Accuracy 0.2149\n",
      "Epoch 36 Batch 100 Loss 1.5083 Accuracy 0.2144\n",
      "Epoch 36 Loss 1.4997 Accuracy 0.2175\n",
      "Time taken for 1 epoch: 410.2270576953888 secs\n",
      "\n",
      "Epoch 37 Batch 0 Loss 1.5233 Accuracy 0.1797\n",
      "Epoch 37 Batch 50 Loss 1.4003 Accuracy 0.2190\n",
      "Epoch 37 Batch 100 Loss 1.3843 Accuracy 0.2169\n",
      "Epoch 37 Loss 1.3820 Accuracy 0.2201\n",
      "Time taken for 1 epoch: 415.5897207260132 secs\n",
      "\n",
      "Epoch 38 Batch 0 Loss 1.3339 Accuracy 0.2367\n",
      "Epoch 38 Batch 50 Loss 1.3501 Accuracy 0.2169\n",
      "Epoch 38 Batch 100 Loss 1.3094 Accuracy 0.2244\n",
      "Epoch 38 Loss 1.3012 Accuracy 0.2273\n",
      "Time taken for 1 epoch: 410.9974617958069 secs\n",
      "\n",
      "Epoch 39 Batch 0 Loss 1.4283 Accuracy 0.1655\n",
      "Epoch 39 Batch 50 Loss 1.2479 Accuracy 0.2313\n",
      "Epoch 39 Batch 100 Loss 1.2041 Accuracy 0.2299\n",
      "Epoch 39 Loss 1.1968 Accuracy 0.2331\n",
      "Time taken for 1 epoch: 408.7576720714569 secs\n",
      "\n",
      "Epoch 40 Batch 0 Loss 1.1381 Accuracy 0.1975\n",
      "Epoch 40 Batch 50 Loss 1.1361 Accuracy 0.2373\n",
      "Epoch 40 Batch 100 Loss 1.1044 Accuracy 0.2354\n",
      "Saving checkpoint for epoch 40 at ./checkpoints/train\\ckpt-8\n",
      "Epoch 40 Loss 1.1007 Accuracy 0.2378\n",
      "Time taken for 1 epoch: 413.5043406486511 secs\n",
      "\n",
      "Epoch 41 Batch 0 Loss 1.1441 Accuracy 0.1936\n",
      "Epoch 41 Batch 50 Loss 1.0378 Accuracy 0.2431\n",
      "Epoch 41 Batch 100 Loss 1.0043 Accuracy 0.2452\n",
      "Epoch 41 Loss 1.0004 Accuracy 0.2481\n",
      "Time taken for 1 epoch: 406.3758981227875 secs\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.9391 Accuracy 0.4245\n",
      "Epoch 42 Batch 50 Loss 0.9472 Accuracy 0.2400\n",
      "Epoch 42 Batch 100 Loss 0.9222 Accuracy 0.2415\n",
      "Epoch 42 Loss 0.9209 Accuracy 0.2448\n",
      "Time taken for 1 epoch: 415.71646666526794 secs\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.9924 Accuracy 0.2020\n",
      "Epoch 43 Batch 50 Loss 0.8824 Accuracy 0.2492\n",
      "Epoch 43 Batch 100 Loss 0.8651 Accuracy 0.2522\n",
      "Epoch 43 Loss 0.8609 Accuracy 0.2555\n",
      "Time taken for 1 epoch: 406.06474566459656 secs\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.8861 Accuracy 0.3954\n",
      "Epoch 44 Batch 50 Loss 0.8198 Accuracy 0.2484\n",
      "Epoch 44 Batch 100 Loss 0.7943 Accuracy 0.2584\n",
      "Epoch 44 Loss 0.7922 Accuracy 0.2600\n",
      "Time taken for 1 epoch: 407.9287793636322 secs\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.7892 Accuracy 0.1895\n",
      "Epoch 45 Batch 50 Loss 0.7476 Accuracy 0.2584\n",
      "Epoch 45 Batch 100 Loss 0.7383 Accuracy 0.2596\n",
      "Saving checkpoint for epoch 45 at ./checkpoints/train\\ckpt-9\n",
      "Epoch 45 Loss 0.7352 Accuracy 0.2627\n",
      "Time taken for 1 epoch: 419.19064497947693 secs\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.7989 Accuracy 0.3438\n",
      "Epoch 46 Batch 50 Loss 0.6966 Accuracy 0.2739\n",
      "Epoch 46 Batch 100 Loss 0.6871 Accuracy 0.2676\n",
      "Epoch 46 Loss 0.6853 Accuracy 0.2724\n",
      "Time taken for 1 epoch: 402.1452605724335 secs\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.6953 Accuracy 0.2494\n",
      "Epoch 47 Batch 50 Loss 0.6465 Accuracy 0.2612\n",
      "Epoch 47 Batch 100 Loss 0.6385 Accuracy 0.2667\n",
      "Epoch 47 Loss 0.6380 Accuracy 0.2700\n",
      "Time taken for 1 epoch: 410.1990089416504 secs\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.5360 Accuracy 0.1844\n",
      "Epoch 48 Batch 50 Loss 0.6024 Accuracy 0.2717\n",
      "Epoch 48 Batch 100 Loss 0.5832 Accuracy 0.2705\n",
      "Epoch 48 Loss 0.5808 Accuracy 0.2722\n",
      "Time taken for 1 epoch: 413.37921118736267 secs\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.5705 Accuracy 0.2604\n",
      "Epoch 49 Batch 50 Loss 0.5889 Accuracy 0.2639\n",
      "Epoch 49 Batch 100 Loss 0.5643 Accuracy 0.2707\n",
      "Epoch 49 Loss 0.5643 Accuracy 0.2729\n",
      "Time taken for 1 epoch: 413.39269948005676 secs\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.5167 Accuracy 0.2182\n",
      "Epoch 50 Batch 50 Loss 0.5290 Accuracy 0.2680\n",
      "Epoch 50 Batch 100 Loss 0.5186 Accuracy 0.2752\n",
      "Saving checkpoint for epoch 50 at ./checkpoints/train\\ckpt-10\n",
      "Epoch 50 Loss 0.5185 Accuracy 0.2761\n",
      "Time taken for 1 epoch: 413.75049662590027 secs\n",
      "\n",
      "Epoch 51 Batch 0 Loss 0.4512 Accuracy 0.1759\n",
      "Epoch 51 Batch 50 Loss 0.5067 Accuracy 0.2822\n",
      "Epoch 51 Batch 100 Loss 0.4912 Accuracy 0.2767\n",
      "Epoch 51 Loss 0.4911 Accuracy 0.2793\n",
      "Time taken for 1 epoch: 412.92141485214233 secs\n",
      "\n",
      "Epoch 52 Batch 0 Loss 0.5520 Accuracy 0.2487\n",
      "Epoch 52 Batch 50 Loss 0.4876 Accuracy 0.2769\n",
      "Epoch 52 Batch 100 Loss 0.4787 Accuracy 0.2837\n",
      "Epoch 52 Loss 0.4758 Accuracy 0.2864\n",
      "Time taken for 1 epoch: 404.010586977005 secs\n",
      "\n",
      "Epoch 53 Batch 0 Loss 0.4493 Accuracy 0.3481\n",
      "Epoch 53 Batch 50 Loss 0.4525 Accuracy 0.2801\n",
      "Epoch 53 Batch 100 Loss 0.4448 Accuracy 0.2829\n",
      "Epoch 53 Loss 0.4433 Accuracy 0.2877\n",
      "Time taken for 1 epoch: 405.20398592948914 secs\n",
      "\n",
      "Epoch 54 Batch 0 Loss 0.4302 Accuracy 0.4342\n",
      "Epoch 54 Batch 50 Loss 0.4190 Accuracy 0.2918\n",
      "Epoch 54 Batch 100 Loss 0.4171 Accuracy 0.2863\n",
      "Epoch 54 Loss 0.4174 Accuracy 0.2867\n",
      "Time taken for 1 epoch: 412.91608023643494 secs\n",
      "\n",
      "Epoch 55 Batch 0 Loss 0.3961 Accuracy 0.4141\n",
      "Epoch 55 Batch 50 Loss 0.3999 Accuracy 0.2916\n",
      "Epoch 55 Batch 100 Loss 0.3903 Accuracy 0.2954\n",
      "Saving checkpoint for epoch 55 at ./checkpoints/train\\ckpt-11\n",
      "Epoch 55 Loss 0.3921 Accuracy 0.2966\n",
      "Time taken for 1 epoch: 406.83835887908936 secs\n",
      "\n",
      "Epoch 56 Batch 0 Loss 0.3767 Accuracy 0.2207\n",
      "Epoch 56 Batch 50 Loss 0.3873 Accuracy 0.2922\n",
      "Epoch 56 Batch 100 Loss 0.3818 Accuracy 0.2919\n",
      "Epoch 56 Loss 0.3782 Accuracy 0.2972\n",
      "Time taken for 1 epoch: 401.10153818130493 secs\n",
      "\n",
      "Epoch 57 Batch 0 Loss 0.3770 Accuracy 0.4748\n",
      "Epoch 57 Batch 50 Loss 0.3563 Accuracy 0.2877\n",
      "Epoch 57 Batch 100 Loss 0.3533 Accuracy 0.2960\n",
      "Epoch 57 Loss 0.3539 Accuracy 0.2993\n",
      "Time taken for 1 epoch: 400.27601289749146 secs\n",
      "\n",
      "Epoch 58 Batch 0 Loss 0.3779 Accuracy 0.1955\n",
      "Epoch 58 Batch 50 Loss 0.3699 Accuracy 0.2935\n",
      "Epoch 58 Batch 100 Loss 0.3584 Accuracy 0.2965\n",
      "Epoch 58 Loss 0.3562 Accuracy 0.2997\n",
      "Time taken for 1 epoch: 400.98547625541687 secs\n",
      "\n",
      "Epoch 59 Batch 0 Loss 0.3044 Accuracy 0.3955\n",
      "Epoch 59 Batch 50 Loss 0.3294 Accuracy 0.2854\n",
      "Epoch 59 Batch 100 Loss 0.3248 Accuracy 0.2881\n",
      "Epoch 59 Loss 0.3238 Accuracy 0.2910\n",
      "Time taken for 1 epoch: 415.3265953063965 secs\n",
      "\n",
      "Epoch 60 Batch 0 Loss 0.2817 Accuracy 0.5221\n",
      "Epoch 60 Batch 50 Loss 0.3234 Accuracy 0.2950\n",
      "Epoch 60 Batch 100 Loss 0.3207 Accuracy 0.2939\n",
      "Saving checkpoint for epoch 60 at ./checkpoints/train\\ckpt-12\n",
      "Epoch 60 Loss 0.3195 Accuracy 0.2975\n",
      "Time taken for 1 epoch: 411.6130299568176 secs\n",
      "\n",
      "Epoch 61 Batch 0 Loss 0.3052 Accuracy 0.2411\n",
      "Epoch 61 Batch 50 Loss 0.3097 Accuracy 0.3011\n",
      "Epoch 61 Batch 100 Loss 0.3062 Accuracy 0.2982\n",
      "Epoch 61 Loss 0.3051 Accuracy 0.3020\n",
      "Time taken for 1 epoch: 410.0849406719208 secs\n",
      "\n",
      "Epoch 62 Batch 0 Loss 0.2474 Accuracy 0.3750\n",
      "Epoch 62 Batch 50 Loss 0.2910 Accuracy 0.3040\n",
      "Epoch 62 Batch 100 Loss 0.2925 Accuracy 0.2953\n",
      "Epoch 62 Loss 0.2940 Accuracy 0.2995\n",
      "Time taken for 1 epoch: 410.8017268180847 secs\n",
      "\n",
      "Epoch 63 Batch 0 Loss 0.2569 Accuracy 0.2467\n",
      "Epoch 63 Batch 50 Loss 0.2783 Accuracy 0.3000\n",
      "Epoch 63 Batch 100 Loss 0.2853 Accuracy 0.2968\n",
      "Epoch 63 Loss 0.2836 Accuracy 0.2982\n",
      "Time taken for 1 epoch: 415.2618088722229 secs\n",
      "\n",
      "Epoch 64 Batch 0 Loss 0.2873 Accuracy 0.2392\n",
      "Epoch 64 Batch 50 Loss 0.2783 Accuracy 0.3005\n",
      "Epoch 64 Batch 100 Loss 0.2780 Accuracy 0.2988\n",
      "Epoch 64 Loss 0.2772 Accuracy 0.3012\n",
      "Time taken for 1 epoch: 409.1138858795166 secs\n",
      "\n",
      "Epoch 65 Batch 0 Loss 0.2706 Accuracy 0.3524\n",
      "Epoch 65 Batch 50 Loss 0.2624 Accuracy 0.2977\n",
      "Epoch 65 Batch 100 Loss 0.2576 Accuracy 0.3005\n",
      "Saving checkpoint for epoch 65 at ./checkpoints/train\\ckpt-13\n",
      "Epoch 65 Loss 0.2563 Accuracy 0.3021\n",
      "Time taken for 1 epoch: 412.15711283683777 secs\n",
      "\n",
      "Epoch 66 Batch 0 Loss 0.3004 Accuracy 0.4121\n",
      "Epoch 66 Batch 50 Loss 0.2644 Accuracy 0.2966\n",
      "Epoch 66 Batch 100 Loss 0.2617 Accuracy 0.2968\n",
      "Epoch 66 Loss 0.2593 Accuracy 0.3009\n",
      "Time taken for 1 epoch: 412.64988446235657 secs\n",
      "\n",
      "Epoch 67 Batch 0 Loss 0.2717 Accuracy 0.2355\n",
      "Epoch 67 Batch 50 Loss 0.2490 Accuracy 0.3006\n",
      "Epoch 67 Batch 100 Loss 0.2471 Accuracy 0.3021\n",
      "Epoch 67 Loss 0.2469 Accuracy 0.3046\n",
      "Time taken for 1 epoch: 411.28191471099854 secs\n",
      "\n",
      "Epoch 68 Batch 0 Loss 0.2522 Accuracy 0.4587\n",
      "Epoch 68 Batch 50 Loss 0.2430 Accuracy 0.3093\n",
      "Epoch 68 Batch 100 Loss 0.2383 Accuracy 0.3056\n",
      "Epoch 68 Loss 0.2369 Accuracy 0.3084\n",
      "Time taken for 1 epoch: 406.52389192581177 secs\n",
      "\n",
      "Epoch 69 Batch 0 Loss 0.2274 Accuracy 0.2506\n",
      "Epoch 69 Batch 50 Loss 0.2360 Accuracy 0.3068\n",
      "Epoch 69 Batch 100 Loss 0.2321 Accuracy 0.3006\n",
      "Epoch 69 Loss 0.2312 Accuracy 0.3022\n",
      "Time taken for 1 epoch: 412.45768642425537 secs\n",
      "\n",
      "Epoch 70 Batch 0 Loss 0.2609 Accuracy 0.2112\n",
      "Epoch 70 Batch 50 Loss 0.2394 Accuracy 0.2953\n",
      "Epoch 70 Batch 100 Loss 0.2333 Accuracy 0.2933\n",
      "Saving checkpoint for epoch 70 at ./checkpoints/train\\ckpt-14\n",
      "Epoch 70 Loss 0.2332 Accuracy 0.2975\n",
      "Time taken for 1 epoch: 422.32996368408203 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 0 Loss 0.1740 Accuracy 0.5012\n",
      "Epoch 71 Batch 50 Loss 0.2179 Accuracy 0.3042\n",
      "Epoch 71 Batch 100 Loss 0.2175 Accuracy 0.3045\n",
      "Epoch 71 Loss 0.2170 Accuracy 0.3072\n",
      "Time taken for 1 epoch: 419.3289303779602 secs\n",
      "\n",
      "Epoch 72 Batch 0 Loss 0.2957 Accuracy 0.2452\n",
      "Epoch 72 Batch 50 Loss 0.2148 Accuracy 0.2912\n",
      "Epoch 72 Batch 100 Loss 0.2132 Accuracy 0.2972\n",
      "Epoch 72 Loss 0.2128 Accuracy 0.2998\n",
      "Time taken for 1 epoch: 420.243940114975 secs\n",
      "\n",
      "Epoch 73 Batch 0 Loss 0.2322 Accuracy 0.2134\n",
      "Epoch 73 Batch 50 Loss 0.2057 Accuracy 0.3087\n",
      "Epoch 73 Batch 100 Loss 0.2090 Accuracy 0.3091\n",
      "Epoch 73 Loss 0.2096 Accuracy 0.3101\n",
      "Time taken for 1 epoch: 407.0264766216278 secs\n",
      "\n",
      "Epoch 74 Batch 0 Loss 0.2264 Accuracy 0.2812\n",
      "Epoch 74 Batch 50 Loss 0.1965 Accuracy 0.3058\n",
      "Epoch 74 Batch 100 Loss 0.1968 Accuracy 0.3012\n",
      "Epoch 74 Loss 0.1973 Accuracy 0.3049\n",
      "Time taken for 1 epoch: 414.826055765152 secs\n",
      "\n",
      "Epoch 75 Batch 0 Loss 0.1838 Accuracy 0.3297\n",
      "Epoch 75 Batch 50 Loss 0.2013 Accuracy 0.3075\n",
      "Epoch 75 Batch 100 Loss 0.2002 Accuracy 0.3015\n",
      "Saving checkpoint for epoch 75 at ./checkpoints/train\\ckpt-15\n",
      "Epoch 75 Loss 0.1998 Accuracy 0.3049\n",
      "Time taken for 1 epoch: 417.3604402542114 secs\n",
      "\n",
      "Epoch 76 Batch 0 Loss 0.2624 Accuracy 0.2266\n",
      "Epoch 76 Batch 50 Loss 0.1988 Accuracy 0.3149\n",
      "Epoch 76 Batch 100 Loss 0.1945 Accuracy 0.3066\n",
      "Epoch 76 Loss 0.1955 Accuracy 0.3119\n",
      "Time taken for 1 epoch: 410.35665917396545 secs\n",
      "\n",
      "Epoch 77 Batch 0 Loss 0.1760 Accuracy 0.4904\n",
      "Epoch 77 Batch 50 Loss 0.1943 Accuracy 0.2931\n",
      "Epoch 77 Batch 100 Loss 0.1937 Accuracy 0.3072\n",
      "Epoch 77 Loss 0.1925 Accuracy 0.3060\n",
      "Time taken for 1 epoch: 416.7665104866028 secs\n",
      "\n",
      "Epoch 78 Batch 0 Loss 0.2285 Accuracy 0.2301\n",
      "Epoch 78 Batch 50 Loss 0.1878 Accuracy 0.3055\n",
      "Epoch 78 Batch 100 Loss 0.1857 Accuracy 0.3035\n",
      "Epoch 78 Loss 0.1850 Accuracy 0.3056\n",
      "Time taken for 1 epoch: 422.82765316963196 secs\n",
      "\n",
      "Epoch 79 Batch 0 Loss 0.1987 Accuracy 0.2394\n",
      "Epoch 79 Batch 50 Loss 0.1893 Accuracy 0.3088\n",
      "Epoch 79 Batch 100 Loss 0.1854 Accuracy 0.3088\n",
      "Epoch 79 Loss 0.1841 Accuracy 0.3122\n",
      "Time taken for 1 epoch: 412.1465196609497 secs\n",
      "\n",
      "Epoch 80 Batch 0 Loss 0.1853 Accuracy 0.3060\n",
      "Epoch 80 Batch 50 Loss 0.1803 Accuracy 0.2986\n",
      "Epoch 80 Batch 100 Loss 0.1755 Accuracy 0.3067\n",
      "Saving checkpoint for epoch 80 at ./checkpoints/train\\ckpt-16\n",
      "Epoch 80 Loss 0.1736 Accuracy 0.3100\n",
      "Time taken for 1 epoch: 420.917409658432 secs\n",
      "\n",
      "Epoch 81 Batch 0 Loss 0.1503 Accuracy 0.2090\n",
      "Epoch 81 Batch 50 Loss 0.1704 Accuracy 0.2930\n",
      "Epoch 81 Batch 100 Loss 0.1746 Accuracy 0.3040\n",
      "Epoch 81 Loss 0.1741 Accuracy 0.3029\n",
      "Time taken for 1 epoch: 425.5957736968994 secs\n",
      "\n",
      "Epoch 82 Batch 0 Loss 0.1828 Accuracy 0.3915\n",
      "Epoch 82 Batch 50 Loss 0.1717 Accuracy 0.2967\n",
      "Epoch 82 Batch 100 Loss 0.1721 Accuracy 0.2984\n",
      "Epoch 82 Loss 0.1720 Accuracy 0.3005\n",
      "Time taken for 1 epoch: 427.5980520248413 secs\n",
      "\n",
      "Epoch 83 Batch 0 Loss 0.1635 Accuracy 0.1728\n",
      "Epoch 83 Batch 50 Loss 0.1748 Accuracy 0.3077\n",
      "Epoch 83 Batch 100 Loss 0.1676 Accuracy 0.3065\n",
      "Epoch 83 Loss 0.1668 Accuracy 0.3094\n",
      "Time taken for 1 epoch: 417.9295189380646 secs\n",
      "\n",
      "Epoch 84 Batch 0 Loss 0.1724 Accuracy 0.4443\n",
      "Epoch 84 Batch 50 Loss 0.1627 Accuracy 0.3013\n",
      "Epoch 84 Batch 100 Loss 0.1579 Accuracy 0.3059\n",
      "Epoch 84 Loss 0.1578 Accuracy 0.3114\n",
      "Time taken for 1 epoch: 416.9500515460968 secs\n",
      "\n",
      "Epoch 85 Batch 0 Loss 0.1256 Accuracy 0.5312\n",
      "Epoch 85 Batch 50 Loss 0.1663 Accuracy 0.3144\n",
      "Epoch 85 Batch 100 Loss 0.1672 Accuracy 0.3147\n",
      "Saving checkpoint for epoch 85 at ./checkpoints/train\\ckpt-17\n",
      "Epoch 85 Loss 0.1666 Accuracy 0.3151\n",
      "Time taken for 1 epoch: 412.1875035762787 secs\n",
      "\n",
      "Epoch 86 Batch 0 Loss 0.1631 Accuracy 0.2129\n",
      "Epoch 86 Batch 50 Loss 0.1577 Accuracy 0.3088\n",
      "Epoch 86 Batch 100 Loss 0.1576 Accuracy 0.3072\n",
      "Epoch 86 Loss 0.1585 Accuracy 0.3101\n",
      "Time taken for 1 epoch: 418.5177812576294 secs\n",
      "\n",
      "Epoch 87 Batch 0 Loss 0.1456 Accuracy 0.3281\n",
      "Epoch 87 Batch 50 Loss 0.1478 Accuracy 0.3021\n",
      "Epoch 87 Batch 100 Loss 0.1482 Accuracy 0.3059\n",
      "Epoch 87 Loss 0.1492 Accuracy 0.3092\n",
      "Time taken for 1 epoch: 422.938809633255 secs\n",
      "\n",
      "Epoch 88 Batch 0 Loss 0.1759 Accuracy 0.3594\n",
      "Epoch 88 Batch 50 Loss 0.1563 Accuracy 0.2978\n",
      "Epoch 88 Batch 100 Loss 0.1559 Accuracy 0.2980\n",
      "Epoch 88 Loss 0.1552 Accuracy 0.3022\n",
      "Time taken for 1 epoch: 428.3578910827637 secs\n",
      "\n",
      "Epoch 89 Batch 0 Loss 0.1484 Accuracy 0.2305\n",
      "Epoch 89 Batch 50 Loss 0.1582 Accuracy 0.3139\n",
      "Epoch 89 Batch 100 Loss 0.1526 Accuracy 0.3090\n",
      "Epoch 89 Loss 0.1526 Accuracy 0.3120\n",
      "Time taken for 1 epoch: 425.8457326889038 secs\n",
      "\n",
      "Epoch 90 Batch 0 Loss 0.1392 Accuracy 0.2285\n",
      "Epoch 90 Batch 50 Loss 0.1500 Accuracy 0.2993\n",
      "Epoch 90 Batch 100 Loss 0.1500 Accuracy 0.3031\n",
      "Saving checkpoint for epoch 90 at ./checkpoints/train\\ckpt-18\n",
      "Epoch 90 Loss 0.1497 Accuracy 0.3080\n",
      "Time taken for 1 epoch: 424.1448528766632 secs\n",
      "\n",
      "Epoch 91 Batch 0 Loss 0.1607 Accuracy 0.3172\n",
      "Epoch 91 Batch 50 Loss 0.1495 Accuracy 0.3045\n",
      "Epoch 91 Batch 100 Loss 0.1447 Accuracy 0.3087\n",
      "Epoch 91 Loss 0.1446 Accuracy 0.3138\n",
      "Time taken for 1 epoch: 418.08207654953003 secs\n",
      "\n",
      "Epoch 92 Batch 0 Loss 0.1289 Accuracy 0.5100\n",
      "Epoch 92 Batch 50 Loss 0.1527 Accuracy 0.3128\n",
      "Epoch 92 Batch 100 Loss 0.1481 Accuracy 0.3096\n",
      "Epoch 92 Loss 0.1482 Accuracy 0.3128\n",
      "Time taken for 1 epoch: 418.9643793106079 secs\n",
      "\n",
      "Epoch 93 Batch 0 Loss 0.1368 Accuracy 0.3047\n",
      "Epoch 93 Batch 50 Loss 0.1427 Accuracy 0.3022\n",
      "Epoch 93 Batch 100 Loss 0.1433 Accuracy 0.3033\n",
      "Epoch 93 Loss 0.1417 Accuracy 0.3052\n",
      "Time taken for 1 epoch: 430.08372044563293 secs\n",
      "\n",
      "Epoch 94 Batch 0 Loss 0.1754 Accuracy 0.4688\n",
      "Epoch 94 Batch 50 Loss 0.1425 Accuracy 0.3052\n",
      "Epoch 94 Batch 100 Loss 0.1388 Accuracy 0.3067\n",
      "Epoch 94 Loss 0.1397 Accuracy 0.3093\n",
      "Time taken for 1 epoch: 422.68267846107483 secs\n",
      "\n",
      "Epoch 95 Batch 0 Loss 0.1799 Accuracy 0.1799\n",
      "Epoch 95 Batch 50 Loss 0.1478 Accuracy 0.3021\n",
      "Epoch 95 Batch 100 Loss 0.1438 Accuracy 0.3025\n",
      "Saving checkpoint for epoch 95 at ./checkpoints/train\\ckpt-19\n",
      "Epoch 95 Loss 0.1435 Accuracy 0.3047\n",
      "Time taken for 1 epoch: 432.2481050491333 secs\n",
      "\n",
      "Epoch 96 Batch 0 Loss 0.1287 Accuracy 0.3242\n",
      "Epoch 96 Batch 50 Loss 0.1485 Accuracy 0.3135\n",
      "Epoch 96 Batch 100 Loss 0.1428 Accuracy 0.3117\n",
      "Epoch 96 Loss 0.1419 Accuracy 0.3154\n",
      "Time taken for 1 epoch: 419.7058765888214 secs\n",
      "\n",
      "Epoch 97 Batch 0 Loss 0.1448 Accuracy 0.2227\n",
      "Epoch 97 Batch 50 Loss 0.1382 Accuracy 0.3023\n",
      "Epoch 97 Batch 100 Loss 0.1365 Accuracy 0.3045\n",
      "Epoch 97 Loss 0.1386 Accuracy 0.3081\n",
      "Time taken for 1 epoch: 430.13008427619934 secs\n",
      "\n",
      "Epoch 98 Batch 0 Loss 0.1552 Accuracy 0.4316\n",
      "Epoch 98 Batch 50 Loss 0.1396 Accuracy 0.3139\n",
      "Epoch 98 Batch 100 Loss 0.1367 Accuracy 0.3133\n",
      "Epoch 98 Loss 0.1370 Accuracy 0.3166\n",
      "Time taken for 1 epoch: 416.14541006088257 secs\n",
      "\n",
      "Epoch 99 Batch 0 Loss 0.1165 Accuracy 0.2196\n",
      "Epoch 99 Batch 50 Loss 0.1254 Accuracy 0.2965\n",
      "Epoch 99 Batch 100 Loss 0.1284 Accuracy 0.3034\n",
      "Epoch 99 Loss 0.1289 Accuracy 0.3076\n",
      "Time taken for 1 epoch: 428.2021541595459 secs\n",
      "\n",
      "Epoch 100 Batch 0 Loss 0.1241 Accuracy 0.4868\n",
      "Epoch 100 Batch 50 Loss 0.1280 Accuracy 0.3130\n",
      "Epoch 100 Batch 100 Loss 0.1278 Accuracy 0.3111\n",
      "Saving checkpoint for epoch 100 at ./checkpoints/train\\ckpt-20\n",
      "Epoch 100 Loss 0.1275 Accuracy 0.3160\n",
      "Time taken for 1 epoch: 421.0666949748993 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  # Save output to TensorBoard\n",
    "  with summary_writer.as_default():\n",
    "    tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch + 1)\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy.result(), step=epoch + 1)\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6APsFrgImLW"
   },
   "source": [
    "The following steps are used for evaluation:\n",
    "\n",
    "* Encode the input sentence using the Portuguese tokenizer (`input_tokenizer`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "* The decoder input is the `start token == target_tokenizer.vocab_size`.\n",
    "* Calculate the padding masks and the look ahead masks.\n",
    "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
    "* Select the last word and calculate the argmax of that.\n",
    "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
    "\n",
    "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [input_tokenizer.vocab_size]\n",
    "  end_token = [input_tokenizer.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + input_tokenizer.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [target_tokenizer.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == target_tokenizer.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "CN-BV43FMBej"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = input_tokenizer.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    # show Chinese character\n",
    "    fontdict = {\"fontproperties\": chinese}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[input_tokenizer.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([target_tokenizer.decode([i]) for i in result \n",
    "                        if i < target_tokenizer.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = target_tokenizer.decode([i for i in result \n",
    "                                            if i < target_tokenizer.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "gZwVWTohOv4_",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a thing that could move fast\n",
      "佢 可以 很 快 地 移動 \n",
      "\n",
      "Input: a thing that could move fast\n",
      "Predicted translation: 佢 可以 很 快 地 移動\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "ran = random.randint(1, len(test_examples))\n",
    "\n",
    "for inp_t, tar_t in test_examples.take(ran):\n",
    "  inp = inp_t.numpy().decode(\"utf-8\")\n",
    "  tar = tar_t.numpy().decode(\"utf-8\")\n",
    "print(inp)\n",
    "print(tar, '\\n')\n",
    "\n",
    "translate(inp, plot='decoder_layer4_block2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_2 (Encoder)          multiple                  1788160   \n",
      "_________________________________________________________________\n",
      "decoder_2 (Decoder)          multiple                  17638528  \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            multiple                  16709757  \n",
      "=================================================================\n",
      "Total params: 36,136,445\n",
      "Trainable params: 36,136,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateTest(sentence):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  sentence = input_tokenizer.encode(sentence)\n",
    "  sentence = ' '.join([input_tokenizer.decode([i]) for i in sentence])\n",
    "  predicted_sentence = target_tokenizer.decode([i for i in result \n",
    "                                            if i < target_tokenizer.vocab_size])  \n",
    "\n",
    "#   print('Input: {}'.format(sentence))\n",
    "#   print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  return sentence, predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50 / 1963 in 44.64314603805542 s\n",
      "Progress: 100 / 1963 in 32.87359976768494 s\n",
      "Progress: 150 / 1963 in 31.314703464508057 s\n",
      "Progress: 200 / 1963 in 36.30274033546448 s\n",
      "Progress: 250 / 1963 in 27.028340578079224 s\n",
      "Progress: 300 / 1963 in 26.13274645805359 s\n",
      "Progress: 350 / 1963 in 31.82491397857666 s\n",
      "Progress: 400 / 1963 in 35.059083700180054 s\n",
      "Progress: 450 / 1963 in 33.45172929763794 s\n",
      "Progress: 500 / 1963 in 35.44756293296814 s\n",
      "Progress: 550 / 1963 in 31.656559228897095 s\n",
      "Progress: 600 / 1963 in 33.709224462509155 s\n",
      "Progress: 650 / 1963 in 28.418901920318604 s\n",
      "Progress: 700 / 1963 in 30.17862629890442 s\n",
      "Progress: 750 / 1963 in 30.37372064590454 s\n",
      "Progress: 800 / 1963 in 29.565354347229004 s\n",
      "Progress: 850 / 1963 in 31.396907806396484 s\n",
      "Progress: 900 / 1963 in 24.839409828186035 s\n",
      "Progress: 950 / 1963 in 29.903717756271362 s\n",
      "Progress: 1000 / 1963 in 31.86581516265869 s\n",
      "Progress: 1050 / 1963 in 35.16303586959839 s\n",
      "Progress: 1100 / 1963 in 32.15205407142639 s\n",
      "Progress: 1150 / 1963 in 36.60993671417236 s\n",
      "Progress: 1200 / 1963 in 37.2580668926239 s\n",
      "Progress: 1250 / 1963 in 36.3830668926239 s\n",
      "Progress: 1300 / 1963 in 27.288607358932495 s\n",
      "Progress: 1350 / 1963 in 34.94180083274841 s\n",
      "Progress: 1400 / 1963 in 30.793224811553955 s\n",
      "Progress: 1450 / 1963 in 30.445749044418335 s\n",
      "Progress: 1500 / 1963 in 36.95654249191284 s\n",
      "Progress: 1550 / 1963 in 30.89931011199951 s\n",
      "Progress: 1600 / 1963 in 31.659127712249756 s\n",
      "Progress: 1650 / 1963 in 23.05354118347168 s\n",
      "Progress: 1700 / 1963 in 45.47695565223694 s\n",
      "Progress: 1750 / 1963 in 44.07251977920532 s\n",
      "Progress: 1800 / 1963 in 30.66903066635132 s\n",
      "Progress: 1850 / 1963 in 47.68008279800415 s\n",
      "Progress: 1900 / 1963 in 33.93272948265076 s\n",
      "Progress: 1950 / 1963 in 37.39260697364807 s\n",
      "Progress: 1963 / 1963 in 1307.2754940986633\n"
     ]
    }
   ],
   "source": [
    "ref = []\n",
    "can = []\n",
    "num_test = 0\n",
    "TotalTime = time.time()\n",
    "start = time.time()\n",
    "for inp_t, tar_t in test_examples:\n",
    "    inp = inp_t.numpy().decode(\"utf-8\")\n",
    "    tar = tar_t.numpy().decode(\"utf-8\")\n",
    "    num_test += 1\n",
    "    if len(inp.split()) < 40 and len(tar.split()) < 40:\n",
    "        inp_r, pre = translateTest(inp)\n",
    "        ref.append([tar.split()])\n",
    "        can.append(pre.split())\n",
    "    if num_test % 50 == 0:\n",
    "        print(f'Progress: {num_test} / {len(test_examples)} in {time.time()-start} s')\n",
    "        start = time.time()\n",
    "        \n",
    "print(f'ToTal: {num_test} / {len(test_examples)} in {time.time()-TotalTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU test result: 75.9623627495366\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "score = 0\n",
    "for i in range(len(ref)):\n",
    "    if YueChar:\n",
    "        score += sentence_bleu(ref[i], can[i])\n",
    "    else:\n",
    "        score += sentence_bleu(ref[i], can[i], weights=(1, 0, 0, 0))\n",
    "print('BLEU test result:', score/len(ref)*100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transformer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
