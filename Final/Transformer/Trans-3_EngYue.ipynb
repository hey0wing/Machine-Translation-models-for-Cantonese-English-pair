{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Transformer model for language understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu2cV7D4kBFi"
   },
   "source": [
    "FYP: Machine translation models for Cantonese-English pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFG0NDRu5mYQ",
    "outputId": "10b72e31-4689-4efc-9406-9dac3da5c01e"
   },
   "outputs": [],
   "source": [
    "!pip install -q tfds-nightly\n",
    "\n",
    "# Pin matplotlib version to 3.2.2 since in the latest version\n",
    "# transformer.ipynb fails with the following error:\n",
    "# https://stackoverflow.com/questions/62953704/valueerror-the-number-of-fixedlocator-locations-5-usually-from-a-call-to-set\n",
    "!pip install -q matplotlib==3.2.2\n",
    "!pip install -q wget\n",
    "\n",
    "!pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd1NWMxjfsDd"
   },
   "source": [
    "## Setup input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "QWviV8YdYh-C",
    "outputId": "6e3bf9d5-5632-4d95-a958-b4196327e03c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yue</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>唔準掂同食醃菜唔準坐梳化或者屋企人嘅床上每次經期完咗要洗床單就算床單無汚糟到他們認為我唔純潔...</td>\n",
       "      <td>I was not allowed to touch or eat pickles I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>佢地扮怪面嚇人</td>\n",
       "      <td>They were making scary faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>唔會搞到我哋變得邪惡女人型變成自由黨人咩</td>\n",
       "      <td>turn us into godless sissy liberals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>呢個模式可以清晰令您瞭解佢哋</td>\n",
       "      <td>So it spells those out in very clean terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>幾多萬億掌聲</td>\n",
       "      <td>How many trillions Applause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 yue  \\\n",
       "0  唔準掂同食醃菜唔準坐梳化或者屋企人嘅床上每次經期完咗要洗床單就算床單無汚糟到他們認為我唔純潔...   \n",
       "1                                            佢地扮怪面嚇人   \n",
       "2                               唔會搞到我哋變得邪惡女人型變成自由黨人咩   \n",
       "3                                     呢個模式可以清晰令您瞭解佢哋   \n",
       "4                                             幾多萬億掌聲   \n",
       "\n",
       "                                                 eng  \n",
       "0  I was not allowed to touch or eat pickles I wa...  \n",
       "1                       They were making scary faces  \n",
       "2                turn us into godless sissy liberals  \n",
       "3         So it spells those out in very clean terms  \n",
       "4                        How many trillions Applause  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "all_csv = glob.glob(os.getcwd() + \"/train.csv\")  \n",
    "\n",
    "df_test = pd.read_csv(os.getcwd() + \"/test.csv\", sep='\\t', encoding='utf-8')  \n",
    "\n",
    "df_from_each_file = (pd.read_csv(f, sep='\\t', encoding='utf-8') for f in all_csv)\n",
    "df = pd.concat(df_from_each_file)\n",
    "\n",
    "# Check for null\n",
    "df[df['yue'].isnull()]\n",
    "df = df.dropna()\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "YueChar = True\n",
    "# Delete spaces between n-gram in Cantonese\n",
    "# Perform Character based tokenization in Cantonese\n",
    "if YueChar:\n",
    "    df['yue'] = df['yue'].str.replace(r' ', '')\n",
    "    df_test['yue'] = df_test['yue'].str.replace(r' ', '')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yue</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>我 相 信 主</td>\n",
       "      <td>I believe the almighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>好 耐 以 嚟 有 發 展 紊 亂 嘅 小 朋 友</td>\n",
       "      <td>For too long now children with developmental d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一 般 會 遇 到 兩 種 反 應</td>\n",
       "      <td>I have two kinds of reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>但 再 諗 下 嗰 位 官 員 未 必 係 唯 一 睇 小 女 性 嘅 人 呢 種 偏 見 ...</td>\n",
       "      <td>But think about this The IMF official is hardl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>佢 將 呢 個 病 毒 傳 畀 BB</td>\n",
       "      <td>She passes that virus on to baby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 yue  \\\n",
       "0                                            我 相 信 主   \n",
       "1                          好 耐 以 嚟 有 發 展 紊 亂 嘅 小 朋 友   \n",
       "2                                  一 般 會 遇 到 兩 種 反 應   \n",
       "3  但 再 諗 下 嗰 位 官 員 未 必 係 唯 一 睇 小 女 性 嘅 人 呢 種 偏 見 ...   \n",
       "4                                 佢 將 呢 個 病 毒 傳 畀 BB   \n",
       "\n",
       "                                                 eng  \n",
       "0                             I believe the almighty  \n",
       "1  For too long now children with developmental d...  \n",
       "2                      I have two kinds of reactions  \n",
       "3  But think about this The IMF official is hardl...  \n",
       "4                   She passes that virus on to baby  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "def spliteKeyWord(str):\n",
    "    regex = r\"[\\u4e00-\\ufaff]|[0-9]+|[a-zA-Z]+\\'*[a-z]*\"\n",
    "    matches = re.findall(regex, str, re.UNICODE)\n",
    "    return ' '.join(matches)\n",
    "\n",
    "if YueChar:\n",
    "    df['yue'] = df['yue'].apply(lambda x: spliteKeyWord(x))\n",
    "    df_test['yue'] = df_test['yue'].apply(lambda x: spliteKeyWord(x))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number: 253040\n",
      "Distinct number: 11503\n",
      "Unique ratio: 0.04545921593423965\n",
      "{'10-99': 1192, '100-999': 432, '1000+': 32, 2: 975, 3: 393, 1: 7651, 8: 101, 9: 72, 4: 262, 5: 178, 7: 103, 6: 112}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "l = ''.join(pd.concat([df, df_test])['yue'].values.tolist()).split()\n",
    "c = Counter(l)\n",
    "print('Total number:', len(l))\n",
    "print('Distinct number:', len(c))\n",
    "print('Unique ratio:', len(c)/len(l))\n",
    "\n",
    "d = {'10-99':0,  '100-999':0,  '1000+':0}\n",
    "for k, v in c.items():\n",
    "    if v<10:\n",
    "        if v in d:\n",
    "            d[v] += 1\n",
    "        else:\n",
    "            d[v] = 1\n",
    "    elif v<100:\n",
    "        d['10-99'] += 1\n",
    "    elif v<1000:\n",
    "        d['100-999'] += 1\n",
    "    else:\n",
    "        d['1000+'] += 1\n",
    "print(d)     \n",
    "labels = list(d.keys())\n",
    "values = list(d.values())\n",
    "\n",
    "# plt.pie(values, labels=labels)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(values, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEsv-c0qqLQd"
   },
   "source": [
    "### Set translational direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0r4EQ67kqKcU"
   },
   "outputs": [],
   "source": [
    "inp_lang = 'eng'\n",
    "tar_lang = 'yue'\n",
    "inp = df[inp_lang]\n",
    "tar = df[tar_lang]\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inp.values, tar.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmVWHYyd18kb"
   },
   "source": [
    "## Split dataset into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UudB9uidSkP",
    "outputId": "b327f1e3-5143-4b79-f204-3d55bed31d2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 7848\n",
      "Test size: 1963\n",
      "\n",
      "Total size: 9811\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE = len(list(dataset))\n",
    "# train_size = int(0.8 * DATASET_SIZE)\n",
    "# test_size = int(0.2 * DATASET_SIZE)\n",
    "\n",
    "# dataset = dataset.shuffle(DATASET_SIZE)\n",
    "train_examples = dataset.take(DATASET_SIZE)\n",
    "# test_examples = dataset.skip(train_size)\n",
    "# test_examples = remaining.take(test_size)\n",
    "# val_examples = remaining.skip(test_size)\n",
    "\n",
    "print('Train size:', len(list(train_examples)))\n",
    "print('Test size:', len(df_test))\n",
    "# print('Validation size:', len(list(val_examples)))\n",
    "print()\n",
    "print('Total size:', DATASET_SIZE + len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5PlJ-TwK6Oi",
    "outputId": "79fdafc4-e9d3-44f5-f231-e059bc58bf09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'I was not allowed to touch or eat pickles I was not allowed to sit on the sofa or some other family member s bed I had to wash my bed sheet after every period even if it was not stained I was considered impure and forbidden from worshipping or touching any object of religious importance You ll find signposts outside temples denying the entry of menstruating girls and women', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe5\\x94\\x94 \\xe6\\xba\\x96 \\xe6\\x8e\\x82 \\xe5\\x90\\x8c \\xe9\\xa3\\x9f \\xe9\\x86\\x83 \\xe8\\x8f\\x9c \\xe5\\x94\\x94 \\xe6\\xba\\x96 \\xe5\\x9d\\x90 \\xe6\\xa2\\xb3 \\xe5\\x8c\\x96 \\xe6\\x88\\x96 \\xe8\\x80\\x85 \\xe5\\xb1\\x8b \\xe4\\xbc\\x81 \\xe4\\xba\\xba \\xe5\\x98\\x85 \\xe5\\xba\\x8a \\xe4\\xb8\\x8a \\xe6\\xaf\\x8f \\xe6\\xac\\xa1 \\xe7\\xb6\\x93 \\xe6\\x9c\\x9f \\xe5\\xae\\x8c \\xe5\\x92\\x97 \\xe8\\xa6\\x81 \\xe6\\xb4\\x97 \\xe5\\xba\\x8a \\xe5\\x96\\xae \\xe5\\xb0\\xb1 \\xe7\\xae\\x97 \\xe5\\xba\\x8a \\xe5\\x96\\xae \\xe7\\x84\\xa1 \\xe6\\xb1\\x9a \\xe7\\xb3\\x9f \\xe5\\x88\\xb0 \\xe4\\xbb\\x96 \\xe5\\x80\\x91 \\xe8\\xaa\\x8d \\xe7\\x82\\xba \\xe6\\x88\\x91 \\xe5\\x94\\x94 \\xe7\\xb4\\x94 \\xe6\\xbd\\x94 \\xe7\\xa6\\x81 \\xe6\\xad\\xa2 \\xe6\\x88\\x91 \\xe5\\x8f\\x83 \\xe6\\x8b\\x9c \\xe6\\x88\\x96 \\xe8\\x80\\x85 \\xe6\\x8e\\x82 \\xe4\\xb8\\x80 \\xe5\\x95\\xb2 \\xe8\\x81\\x96 \\xe7\\x89\\xa9 \\xe4\\xbd\\xa0 \\xe6\\x9c\\x83 \\xe7\\x99\\xbc \\xe7\\x8f\\xbe \\xe5\\xaf\\xba \\xe5\\xbb\\x9f \\xe5\\x87\\xba \\xe9\\x9d\\xa2 \\xe6\\x9c\\x89 \\xe7\\x89\\x8c \\xe8\\xb7\\xaf \\xe7\\x89\\x8c \\xe7\\xa6\\x81 \\xe6\\xad\\xa2 \\xe6\\xad\\xa3 \\xe5\\x9c\\xa8 \\xe5\\x9a\\x9f \\xe7\\xb7\\x8a \\xe7\\xb6\\x93 \\xe6\\x9c\\x9f \\xe5\\x98\\x85 \\xe5\\xa9\\xa6 \\xe5\\xa5\\xb3 \\xe9\\x80\\xb2 \\xe5\\x85\\xa5', shape=(), dtype=string)\n",
      "----------\n",
      "tf.Tensor(b'They were making scary faces', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe4\\xbd\\xa2 \\xe5\\x9c\\xb0 \\xe6\\x89\\xae \\xe6\\x80\\xaa \\xe9\\x9d\\xa2 \\xe5\\x9a\\x87 \\xe4\\xba\\xba', shape=(), dtype=string)\n",
      "----------\n",
      "tf.Tensor(b'turn us into godless sissy liberals', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe5\\x94\\x94 \\xe6\\x9c\\x83 \\xe6\\x90\\x9e \\xe5\\x88\\xb0 \\xe6\\x88\\x91 \\xe5\\x93\\x8b \\xe8\\xae\\x8a \\xe5\\xbe\\x97 \\xe9\\x82\\xaa \\xe6\\x83\\xa1 \\xe5\\xa5\\xb3 \\xe4\\xba\\xba \\xe5\\x9e\\x8b \\xe8\\xae\\x8a \\xe6\\x88\\x90 \\xe8\\x87\\xaa \\xe7\\x94\\xb1 \\xe9\\xbb\\xa8 \\xe4\\xba\\xba \\xe5\\x92\\xa9', shape=(), dtype=string)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for inp, tar in train_examples.take(3):\n",
    "  print(inp)\n",
    "  print(tar)\n",
    "  print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "waK4jpjpw2dZ",
    "outputId": "9146e9e0-0437-4f39-a30a-02c9df423afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was not allowed to touch or eat pickles I was not allowed to sit on the sofa or some other family member s bed I had to wash my bed sheet after every period even if it was not stained I was considered impure and forbidden from worshipping or touching any object of religious importance You ll find signposts outside temples denying the entry of menstruating girls and women\n",
      "唔 準 掂 同 食 醃 菜 唔 準 坐 梳 化 或 者 屋 企 人 嘅 床 上 每 次 經 期 完 咗 要 洗 床 單 就 算 床 單 無 汚 糟 到 他 們 認 為 我 唔 純 潔 禁 止 我 參 拜 或 者 掂 一 啲 聖 物 你 會 發 現 寺 廟 出 面 有 牌 路 牌 禁 止 正 在 嚟 緊 經 期 嘅 婦 女 進 入\n",
      "----------\n",
      "They were making scary faces\n",
      "佢 地 扮 怪 面 嚇 人\n",
      "----------\n",
      "turn us into godless sissy liberals\n",
      "唔 會 搞 到 我 哋 變 得 邪 惡 女 人 型 變 成 自 由 黨 人 咩\n",
      "----------\n",
      "So it spells those out in very clean terms\n",
      "呢 個 模 式 可 以 清 晰 令 您 瞭 解 佢 哋\n",
      "----------\n",
      "How many trillions Applause\n",
      "幾 多 萬 億 掌 聲\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "sample_examples = []\n",
    "num_samples = 5\n",
    "\n",
    "for inp_t, tar_t in train_examples.take(num_samples):\n",
    "  inp = inp_t.numpy().decode(\"utf-8\")\n",
    "  tar = tar_t.numpy().decode(\"utf-8\")\n",
    "  \n",
    "  print(inp)\n",
    "  print(tar)\n",
    "  print('-' * 10)\n",
    "  \n",
    "  sample_examples.append((inp, tar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inp_lang == 'yue':\n",
    "    if YueChar:\n",
    "      input_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "          (inp.numpy() for inp, tar in train_examples), target_vocab_size=2**13, max_subword_length=1)\n",
    "    else:\n",
    "      input_tokenizer = tfds.deprecated.text.TokenTextEncoder(\n",
    "          ' '.join(inp.numpy().decode(\"utf-8\") for inp, tar in train_examples).split(' ')) \n",
    "    target_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "        (tar.numpy() for inp, tar in train_examples), target_vocab_size=2**13)\n",
    "else:\n",
    "    if YueChar:\n",
    "      target_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "          (tar.numpy() for inp, tar in train_examples), target_vocab_size=2**13, max_subword_length=1)\n",
    "    else:\n",
    "      target_tokenizer = tfds.deprecated.text.TokenTextEncoder(\n",
    "          ' '.join(tar.numpy().decode(\"utf-8\") for inp, tar in train_examples).split(' '))\n",
    "    input_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "      (inp.numpy() for inp, tar in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng: 7791 vocabs\n",
      "yue: 3335 vocabs\n"
     ]
    }
   ],
   "source": [
    "print(f'{inp_lang}: {input_tokenizer.vocab_size} vocabs')\n",
    "print(f'{tar_lang}: {target_tokenizer.vocab_size} vocabs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-PPeXeT4WHN"
   },
   "source": [
    "Check the tokenizers with sample string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DYWukNFkGQN",
    "outputId": "902864c3-fa59-45c0-e8f9-17536d62fea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [6, 15, 28, 1290, 2, 2160, 36, 436, 2551, 951, 6, 15, 28, 1290, 2, 1335, 21, 1, 5696, 5, 36, 89, 101, 282, 2248, 7, 1521, 6, 61, 2, 2140, 25, 1521, 5743, 208, 162, 943, 116, 63, 12, 15, 28, 4338, 2573, 6, 15, 2351, 2007, 1122, 3, 4854, 2057, 39, 5395, 1140, 36, 5536, 159, 1971, 4, 2945, 6413, 64, 127, 194, 1728, 1453, 7, 1350, 2878, 951, 1641, 1878, 1, 3906, 85, 4, 6204, 467, 3, 1046]\n",
      "The original string: I was not allowed to touch or eat pickles I was not allowed to sit on the sofa or some other family member s bed I had to wash my bed sheet after every period even if it was not stained I was considered impure and forbidden from worshipping or touching any object of religious importance You ll find signposts outside temples denying the entry of menstruating girls and women\n",
      "Tokenized string is [14, 3111, 554, 3111, 980, 3111, 10, 3111, 116, 3111, 2303, 3111, 1225, 3111, 14, 3111, 554, 3111, 583, 3111, 2196, 3111, 153, 3111, 102, 3111, 67, 3111, 331, 3111, 252, 3111, 9, 3111, 1, 3111, 942, 3111, 37, 3111, 150, 3111, 184, 3111, 55, 3111, 298, 3111, 307, 3111, 25, 3111, 23, 3111, 934, 3111, 942, 3111, 190, 3111, 19, 3111, 437, 3111, 942, 3111, 190, 3111, 75, 3111, 2858, 3111, 1773, 3111, 16, 3111, 141, 3111, 357, 3111, 229, 3111, 24, 3111, 2, 3111, 14, 3111, 1097, 3111, 1794, 3111, 1069, 3111, 312, 3111, 2, 3111, 675, 3111, 824, 3111, 102, 3111, 67, 3111, 980, 3111, 5, 3111, 22, 3111, 677, 3111, 79, 3111, 12, 3111, 17, 3111, 51, 3111, 111, 3111, 2057, 3111, 2949, 3111, 63, 3111, 61, 3111, 7, 3111, 1024, 3111, 165, 3111, 1024, 3111, 1069, 3111, 312, 3111, 187, 3111, 162, 3111, 47, 3111, 179, 3111, 55, 3111, 298, 3111, 1, 3111, 982, 3111, 113, 3111, 319, 3111, 120]\n",
      "The original string: 唔 準 掂 同 食 醃 菜 唔 準 坐 梳 化 或 者 屋 企 人 嘅 床 上 每 次 經 期 完 咗 要 洗 床 單 就 算 床 單 無 汚 糟 到 他 們 認 為 我 唔 純 潔 禁 止 我 參 拜 或 者 掂 一 啲 聖 物 你 會 發 現 寺 廟 出 面 有 牌 路 牌 禁 止 正 在 嚟 緊 經 期 嘅 婦 女 進 入\n"
     ]
    }
   ],
   "source": [
    "# We can use string in dataset\n",
    "sample_inp = sample_examples[0][0]\n",
    "sample_tar = sample_examples[0][1]\n",
    "\n",
    "tokenized_inp = input_tokenizer.encode(sample_inp)\n",
    "print ('Tokenized string is {}'.format(tokenized_inp))\n",
    "\n",
    "original_inp = input_tokenizer.decode(tokenized_inp)\n",
    "print ('The original string: {}'.format(original_inp))\n",
    "\n",
    "tokenized_tar = target_tokenizer.encode(sample_tar)\n",
    "print ('Tokenized string is {}'.format(tokenized_tar))\n",
    "\n",
    "original_tar = target_tokenizer.decode(tokenized_tar)\n",
    "print ('The original string: {}'.format(original_tar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9KJWJjrsZ4Y"
   },
   "source": [
    "The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf2ntBxjkqK6",
    "outputId": "0234d439-6ab8-45ac-9591-71051d640c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 ----> I \n",
      "15 ----> was \n",
      "28 ----> not \n",
      "1290 ----> allowed \n",
      "2 ----> to \n",
      "2160 ----> touch \n",
      "36 ----> or \n",
      "436 ----> eat \n",
      "2551 ----> pick\n",
      "951 ----> les \n",
      "6 ----> I \n",
      "15 ----> was \n",
      "28 ----> not \n",
      "1290 ----> allowed \n",
      "2 ----> to \n",
      "1335 ----> sit \n",
      "21 ----> on \n",
      "1 ----> the \n",
      "5696 ----> sof\n",
      "5 ----> a \n",
      "36 ----> or \n",
      "89 ----> some \n",
      "101 ----> other \n",
      "282 ----> family \n",
      "2248 ----> member \n",
      "7 ----> s \n",
      "1521 ----> bed \n",
      "6 ----> I \n",
      "61 ----> had \n",
      "2 ----> to \n",
      "2140 ----> wash \n",
      "25 ----> my \n",
      "1521 ----> bed \n",
      "5743 ----> sheet \n",
      "208 ----> after \n",
      "162 ----> every \n",
      "943 ----> period \n",
      "116 ----> even \n",
      "63 ----> if \n",
      "12 ----> it \n",
      "15 ----> was \n",
      "28 ----> not \n",
      "4338 ----> stai\n",
      "2573 ----> ned \n",
      "6 ----> I \n",
      "15 ----> was \n",
      "2351 ----> considered \n",
      "2007 ----> imp\n",
      "1122 ----> ure \n",
      "3 ----> and \n",
      "4854 ----> forbid\n",
      "2057 ----> den \n",
      "39 ----> from \n",
      "5395 ----> worship\n",
      "1140 ----> ping \n",
      "36 ----> or \n",
      "5536 ----> touching \n",
      "159 ----> any \n",
      "1971 ----> object \n",
      "4 ----> of \n",
      "2945 ----> religious \n",
      "6413 ----> importance \n",
      "64 ----> You \n",
      "127 ----> ll \n",
      "194 ----> find \n",
      "1728 ----> sign\n",
      "1453 ----> post\n",
      "7 ----> s \n",
      "1350 ----> outside \n",
      "2878 ----> temp\n",
      "951 ----> les \n",
      "1641 ----> den\n",
      "1878 ----> ying \n",
      "1 ----> the \n",
      "3906 ----> entr\n",
      "85 ----> y \n",
      "4 ----> of \n",
      "6204 ----> menstruating \n",
      "467 ----> girls \n",
      "3 ----> and \n",
      "1046 ----> women\n",
      "\n",
      "14 ----> 唔\n",
      "3111 ---->  \n",
      "554 ----> 準\n",
      "3111 ---->  \n",
      "980 ----> 掂\n",
      "3111 ---->  \n",
      "10 ----> 同\n",
      "3111 ---->  \n",
      "116 ----> 食\n",
      "3111 ---->  \n",
      "2303 ----> 醃\n",
      "3111 ---->  \n",
      "1225 ----> 菜\n",
      "3111 ---->  \n",
      "14 ----> 唔\n",
      "3111 ---->  \n",
      "554 ----> 準\n",
      "3111 ---->  \n",
      "583 ----> 坐\n",
      "3111 ---->  \n",
      "2196 ----> 梳\n",
      "3111 ---->  \n",
      "153 ----> 化\n",
      "3111 ---->  \n",
      "102 ----> 或\n",
      "3111 ---->  \n",
      "67 ----> 者\n",
      "3111 ---->  \n",
      "331 ----> 屋\n",
      "3111 ---->  \n",
      "252 ----> 企\n",
      "3111 ---->  \n",
      "9 ----> 人\n",
      "3111 ---->  \n",
      "1 ----> 嘅\n",
      "3111 ---->  \n",
      "942 ----> 床\n",
      "3111 ---->  \n",
      "37 ----> 上\n",
      "3111 ---->  \n",
      "150 ----> 每\n",
      "3111 ---->  \n",
      "184 ----> 次\n",
      "3111 ---->  \n",
      "55 ----> 經\n",
      "3111 ---->  \n",
      "298 ----> 期\n",
      "3111 ---->  \n",
      "307 ----> 完\n",
      "3111 ---->  \n",
      "25 ----> 咗\n",
      "3111 ---->  \n",
      "23 ----> 要\n",
      "3111 ---->  \n",
      "934 ----> 洗\n",
      "3111 ---->  \n",
      "942 ----> 床\n",
      "3111 ---->  \n",
      "190 ----> 單\n",
      "3111 ---->  \n",
      "19 ----> 就\n",
      "3111 ---->  \n",
      "437 ----> 算\n",
      "3111 ---->  \n",
      "942 ----> 床\n",
      "3111 ---->  \n",
      "190 ----> 單\n",
      "3111 ---->  \n",
      "75 ----> 無\n",
      "3111 ---->  \n",
      "2858 ----> 汚\n",
      "3111 ---->  \n",
      "1773 ----> 糟\n",
      "3111 ---->  \n",
      "16 ----> 到\n",
      "3111 ---->  \n",
      "141 ----> 他\n",
      "3111 ---->  \n",
      "357 ----> 們\n",
      "3111 ---->  \n",
      "229 ----> 認\n",
      "3111 ---->  \n",
      "24 ----> 為\n",
      "3111 ---->  \n",
      "2 ----> 我\n",
      "3111 ---->  \n",
      "14 ----> 唔\n",
      "3111 ---->  \n",
      "1097 ----> 純\n",
      "3111 ---->  \n",
      "1794 ----> 潔\n",
      "3111 ---->  \n",
      "1069 ----> 禁\n",
      "3111 ---->  \n",
      "312 ----> 止\n",
      "3111 ---->  \n",
      "2 ----> 我\n",
      "3111 ---->  \n",
      "675 ----> 參\n",
      "3111 ---->  \n",
      "824 ----> 拜\n",
      "3111 ---->  \n",
      "102 ----> 或\n",
      "3111 ---->  \n",
      "67 ----> 者\n",
      "3111 ---->  \n",
      "980 ----> 掂\n",
      "3111 ---->  \n",
      "5 ----> 一\n",
      "3111 ---->  \n",
      "22 ----> 啲\n",
      "3111 ---->  \n",
      "677 ----> 聖\n",
      "3111 ---->  \n",
      "79 ----> 物\n",
      "3111 ---->  \n",
      "12 ----> 你\n",
      "3111 ---->  \n",
      "17 ----> 會\n",
      "3111 ---->  \n",
      "51 ----> 發\n",
      "3111 ---->  \n",
      "111 ----> 現\n",
      "3111 ---->  \n",
      "2057 ----> 寺\n",
      "3111 ---->  \n",
      "2949 ----> 廟\n",
      "3111 ---->  \n",
      "63 ----> 出\n",
      "3111 ---->  \n",
      "61 ----> 面\n",
      "3111 ---->  \n",
      "7 ----> 有\n",
      "3111 ---->  \n",
      "1024 ----> 牌\n",
      "3111 ---->  \n",
      "165 ----> 路\n",
      "3111 ---->  \n",
      "1024 ----> 牌\n",
      "3111 ---->  \n",
      "1069 ----> 禁\n",
      "3111 ---->  \n",
      "312 ----> 止\n",
      "3111 ---->  \n",
      "187 ----> 正\n",
      "3111 ---->  \n",
      "162 ----> 在\n",
      "3111 ---->  \n",
      "47 ----> 嚟\n",
      "3111 ---->  \n",
      "179 ----> 緊\n",
      "3111 ---->  \n",
      "55 ----> 經\n",
      "3111 ---->  \n",
      "298 ----> 期\n",
      "3111 ---->  \n",
      "1 ----> 嘅\n",
      "3111 ---->  \n",
      "982 ----> 婦\n",
      "3111 ---->  \n",
      "113 ----> 女\n",
      "3111 ---->  \n",
      "319 ----> 進\n",
      "3111 ---->  \n",
      "120 ----> 入\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_inp:\n",
    "  print ('{} ----> {}'.format(ts, input_tokenizer.decode([ts])))\n",
    "print()\n",
    "for ts in tokenized_tar:\n",
    "  print ('{} ----> {}'.format(ts, target_tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGi4PoVakxdc"
   },
   "source": [
    "Add a start and end token to the input and target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UZwnPr4R055s"
   },
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  lang1 = [input_tokenizer.vocab_size] + input_tokenizer.encode(\n",
    "      lang1.numpy()) + [input_tokenizer.vocab_size+1]\n",
    "\n",
    "  lang2 = [target_tokenizer.vocab_size] + target_tokenizer.encode(\n",
    "      lang2.numpy()) + [target_tokenizer.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tx1sFbR-9fRs"
   },
   "source": [
    "You want to use `Dataset.map` to apply this function to each element of the dataset.  `Dataset.map` runs in graph mode.\n",
    "\n",
    "* Graph tensors do not have a value. \n",
    "* In graph mode you can only use TensorFlow Ops and functions. \n",
    "\n",
    "So you can't `.map` this function directly: You need to wrap it in a `tf.py_function`. The `tf.py_function` will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Mah1cS-P70Iz"
   },
   "outputs": [],
   "source": [
    "def tf_encode(inp, tar):\n",
    "  result_inp, result_tar = tf.py_function(encode, [inp, tar], [tf.int64, tf.int64])\n",
    "  result_inp.set_shape([None])\n",
    "  result_tar.set_shape([None])\n",
    "\n",
    "  return result_inp, result_tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JrGp5Gek6Ql"
   },
   "source": [
    "Note: To keep this example small and relatively fast, drop examples with a length of over `40` tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "c081xPGv1CPI"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mk9AZdZ5bcS",
    "outputId": "28e59114-d36d-48c8-bf9d-cef2b24049c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 6634\n",
      "Testing size: 1696\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "num_examples = 0\n",
    "for inp_indices, tar_indices in train_dataset:\n",
    "  num_examples += 1\n",
    "print(f\"Training size: {num_examples}\")\n",
    "\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "df_test = df_test[\n",
    "    df_test['yue'].apply(lambda x: len(x.split())<MAX_LENGTH) &\n",
    "    df_test['eng'].apply(lambda x: len(x.split())<MAX_LENGTH) \n",
    "]\n",
    "\n",
    "print(f\"Testing size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RgYUtEECc-Q",
    "outputId": "949dd9c4-d890-4991-f1c7-bebcb9e9c6c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[7791   34    7 ...    0    0    0]\n",
      " [7791   11    1 ...    0    0    0]\n",
      " [7791   14  226 ...    0    0    0]\n",
      " ...\n",
      " [7791    9 5277 ...    0    0    0]\n",
      " [7791  147    7 ...    0    0    0]\n",
      " [7791  356 6255 ...    0    0    0]], shape=(64, 21), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[3335    8 3111 ...    0    0    0]\n",
      " [3335   19 3111 ...    0    0    0]\n",
      " [3335  247 3111 ...    0    0    0]\n",
      " ...\n",
      " [3335 3129 3127 ...    0    0    0]\n",
      " [3335  534 3111 ...    0    0    0]\n",
      " [3335  227 3111 ...    0    0    0]], shape=(64, 39), dtype=int64)\n",
      "\n",
      "All string are less than 40 tokens\n",
      "Total batches: 104\n"
     ]
    }
   ],
   "source": [
    "# Check with train set\n",
    "inp_indices, tar_indices  = next(iter(train_dataset))\n",
    "print(inp_indices)\n",
    "print(tar_indices)\n",
    "\n",
    "num_examples = 0\n",
    "for inp_indices, tar_indices in train_dataset:\n",
    "  # cond1 = len(inp_indices) <= MAX_LENGTH\n",
    "  # cond2 = len(tar_indices) <= MAX_LENGTH\n",
    "  # assert cond1 and cond2\n",
    "  num_examples += 1\n",
    "\n",
    "print(f\"\\nAll string are less than {MAX_LENGTH} tokens\")\n",
    "print(f\"Total batches: {num_examples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "1kLCla68EloE",
    "outputId": "4595b67d-9fc7-45a2-8678-fbe51c8d8e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7BYeBCNvi7n",
    "outputId": "2f526483-7e23-49b8-b05e-d76a9c3d654a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxKGuXxaBeeE",
    "outputId": "afa5b144-c85f-4626-e942-12d24586fc9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsxEE_-Wa1gF"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "The attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. \n",
    "\n",
    "For example, consider that `Q` and `K` have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of `dk`. Hence, *square root of `dk`* is used for scaling (and not any other number) because the matmul of `Q` and `K` should have a mean of 0 and variance of 1, and you get a gentler softmax.\n",
    "\n",
    "The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiqETnhCkoXh"
   },
   "source": [
    "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
    "\n",
    "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "n90YjClyInFy"
   },
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAzUAf2DPlNt",
    "outputId": "4f614ff2-a52f-4c81-f5d2-f35876de949d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zg6k-fGhgXra",
    "outputId": "82585d6b-4d8c-411b-c868-7b6343409b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UAq3YOzUgXhb",
    "outputId": "c38b7220-1ced-4987-e510-f34c4f12fe69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOz-4_XIhaTP"
   },
   "source": [
    "Pass all the queries together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dlU8Tm-hYrF",
    "outputId": "4f80eeaf-12c1-4819-ad59-d39bcab1bb2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hu94p-_-2_BX",
    "outputId": "8f890a1d-970e-40d3-ee5d-15d4fa4ac349"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mytb1lPyOHLB",
    "outputId": "b9ba0e9b-1dd9-47b2-be13-3ec500cc6d57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzZRXdO0mI48",
    "outputId": "f782e377-bc21-4e2b-9088-32b8538f85c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### Decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne2Bqx8k71l0",
    "outputId": "53c7b26c-e654-4dc6-ef3b-613bff14234e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QG9nueFQKXx",
    "outputId": "c1c5cc6b-19bb-4190-c8d7-f605fb303c07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1jXoAMRZyvu",
    "outputId": "49e16979-6f48-4c6c-c307-0b95259d725e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## Create the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJ4fbQcIkHW1",
    "outputId": "6bc6155a-02f0-44ff-b04d-5ab4b4c387cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
    "\n",
    "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
    "\n",
    "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "d_model = 32\n",
    "dff = 128\n",
    "num_heads = 4\n",
    "\n",
    "input_vocab_size = input_tokenizer.vocab_size + 2\n",
    "target_vocab_size = target_tokenizer.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "f33ZCgvHpPdG",
    "outputId": "d32a1d68-c675-424d-ddc5-855608622ba6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/Trans-3_EngYue\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "# if ckpt_manager.latest_checkpoint:\n",
    "#   ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "#   print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 2).\n",
       "Contents of stderr:\n",
       "2021-04-15 22:23:31.308617: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
       "2021-04-15 22:23:31.308764: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
       "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
       "                   [--host ADDR] [--bind_all] [--port PORT]\n",
       "                   [--purge_orphaned_data BOOL] [--db URI] [--db_import]\n",
       "                   [--inspect] [--version_tb] [--tag TAG] [--event_file PATH]\n",
       "                   [--path_prefix PATH] [--window_title TEXT]\n",
       "                   [--max_reload_threads COUNT] [--reload_interval SECONDS]\n",
       "                   [--reload_task TYPE] [--reload_multifile BOOL]\n",
       "                   [--reload_multifile_inactive_secs SECONDS]\n",
       "                   [--generic_data TYPE]\n",
       "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
       "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
       "                   {serve,dev} ...\n",
       "tensorboard: error: invalid choice: 'sem1COMP4801JupyterlogEngYue_2layers_32d_4heads_128dff_100EPOCHS_TrueYueChar' (choose from 'serve', 'dev')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_id = f\"Trans-3_EngYue_{num_layers}L_{d_model}D_{num_heads}H_{dff}dff\"\n",
    "log_dir = os.path.join(os.path.join(os.getcwd(), 'log'), run_id)\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbvmaKNiznHZ",
    "outputId": "f6bc5b1f-c9b6-4cb7-839f-70abab2c8905",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.1428 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.0910 Accuracy 0.0001\n",
      "Epoch 1 Batch 100 Loss 7.9927 Accuracy 0.0548\n",
      "Epoch 1 Loss 7.9869 Accuracy 0.0587\n",
      "Time taken for 1 epoch: 28.299363136291504 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 7.7832 Accuracy 0.2131\n",
      "Epoch 2 Batch 50 Loss 7.6667 Accuracy 0.2249\n",
      "Epoch 2 Batch 100 Loss 7.5317 Accuracy 0.2238\n",
      "Epoch 2 Loss 7.5232 Accuracy 0.2240\n",
      "Time taken for 1 epoch: 19.670082807540894 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 7.1982 Accuracy 0.2327\n",
      "Epoch 3 Batch 50 Loss 7.0321 Accuracy 0.2261\n",
      "Epoch 3 Batch 100 Loss 6.8318 Accuracy 0.2247\n",
      "Epoch 3 Loss 6.8195 Accuracy 0.2249\n",
      "Time taken for 1 epoch: 21.759112119674683 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 6.3775 Accuracy 0.2220\n",
      "Epoch 4 Batch 50 Loss 6.1557 Accuracy 0.2277\n",
      "Epoch 4 Batch 100 Loss 5.9155 Accuracy 0.2245\n",
      "Epoch 4 Loss 5.9030 Accuracy 0.2241\n",
      "Time taken for 1 epoch: 19.8461332321167 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 5.3750 Accuracy 0.2134\n",
      "Epoch 5 Batch 50 Loss 5.1650 Accuracy 0.2251\n",
      "Epoch 5 Batch 100 Loss 4.9287 Accuracy 0.2233\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-1\n",
      "Epoch 5 Loss 4.9146 Accuracy 0.2233\n",
      "Time taken for 1 epoch: 21.4634792804718 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 4.4913 Accuracy 0.1970\n",
      "Epoch 6 Batch 50 Loss 4.2908 Accuracy 0.2246\n",
      "Epoch 6 Batch 100 Loss 4.1119 Accuracy 0.2222\n",
      "Epoch 6 Loss 4.1035 Accuracy 0.2220\n",
      "Time taken for 1 epoch: 19.677249908447266 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 3.7873 Accuracy 0.2358\n",
      "Epoch 7 Batch 50 Loss 3.6699 Accuracy 0.2248\n",
      "Epoch 7 Batch 100 Loss 3.5946 Accuracy 0.2237\n",
      "Epoch 7 Loss 3.5912 Accuracy 0.2235\n",
      "Time taken for 1 epoch: 19.787068367004395 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 3.4652 Accuracy 0.1974\n",
      "Epoch 8 Batch 50 Loss 3.4215 Accuracy 0.2326\n",
      "Epoch 8 Batch 100 Loss 3.3831 Accuracy 0.2344\n",
      "Epoch 8 Loss 3.3808 Accuracy 0.2345\n",
      "Time taken for 1 epoch: 19.45458221435547 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 3.3277 Accuracy 0.2488\n",
      "Epoch 9 Batch 50 Loss 3.2979 Accuracy 0.2421\n",
      "Epoch 9 Batch 100 Loss 3.2682 Accuracy 0.2409\n",
      "Epoch 9 Loss 3.2687 Accuracy 0.2412\n",
      "Time taken for 1 epoch: 19.510598182678223 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 3.2738 Accuracy 0.2270\n",
      "Epoch 10 Batch 50 Loss 3.2177 Accuracy 0.2464\n",
      "Epoch 10 Batch 100 Loss 3.1936 Accuracy 0.2462\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-2\n",
      "Epoch 10 Loss 3.1933 Accuracy 0.2456\n",
      "Time taken for 1 epoch: 19.676738739013672 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 3.0871 Accuracy 0.2660\n",
      "Epoch 11 Batch 50 Loss 3.1570 Accuracy 0.2476\n",
      "Epoch 11 Batch 100 Loss 3.1367 Accuracy 0.2479\n",
      "Epoch 11 Loss 3.1369 Accuracy 0.2478\n",
      "Time taken for 1 epoch: 19.415475845336914 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 3.0561 Accuracy 0.2418\n",
      "Epoch 12 Batch 50 Loss 3.1112 Accuracy 0.2484\n",
      "Epoch 12 Batch 100 Loss 3.0861 Accuracy 0.2494\n",
      "Epoch 12 Loss 3.0849 Accuracy 0.2497\n",
      "Time taken for 1 epoch: 19.488637924194336 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 3.1029 Accuracy 0.2348\n",
      "Epoch 13 Batch 50 Loss 3.0575 Accuracy 0.2528\n",
      "Epoch 13 Batch 100 Loss 3.0337 Accuracy 0.2527\n",
      "Epoch 13 Loss 3.0327 Accuracy 0.2527\n",
      "Time taken for 1 epoch: 19.945676803588867 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 3.0055 Accuracy 0.2309\n",
      "Epoch 14 Batch 50 Loss 3.0057 Accuracy 0.2575\n",
      "Epoch 14 Batch 100 Loss 2.9769 Accuracy 0.2569\n",
      "Epoch 14 Loss 2.9757 Accuracy 0.2564\n",
      "Time taken for 1 epoch: 20.821678638458252 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 3.0124 Accuracy 0.2560\n",
      "Epoch 15 Batch 50 Loss 2.9452 Accuracy 0.2614\n",
      "Epoch 15 Batch 100 Loss 2.9204 Accuracy 0.2598\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-3\n",
      "Epoch 15 Loss 2.9197 Accuracy 0.2597\n",
      "Time taken for 1 epoch: 20.16422986984253 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 2.7796 Accuracy 0.2313\n",
      "Epoch 16 Batch 50 Loss 2.8820 Accuracy 0.2600\n",
      "Epoch 16 Batch 100 Loss 2.8600 Accuracy 0.2613\n",
      "Epoch 16 Loss 2.8579 Accuracy 0.2616\n",
      "Time taken for 1 epoch: 19.598747968673706 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 2.7849 Accuracy 0.2617\n",
      "Epoch 17 Batch 50 Loss 2.8287 Accuracy 0.2671\n",
      "Epoch 17 Batch 100 Loss 2.8004 Accuracy 0.2659\n",
      "Epoch 17 Loss 2.7991 Accuracy 0.2658\n",
      "Time taken for 1 epoch: 19.787591695785522 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 2.7248 Accuracy 0.2535\n",
      "Epoch 18 Batch 50 Loss 2.7682 Accuracy 0.2656\n",
      "Epoch 18 Batch 100 Loss 2.7411 Accuracy 0.2683\n",
      "Epoch 18 Loss 2.7387 Accuracy 0.2684\n",
      "Time taken for 1 epoch: 22.111572980880737 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 2.6596 Accuracy 0.2725\n",
      "Epoch 19 Batch 50 Loss 2.6968 Accuracy 0.2707\n",
      "Epoch 19 Batch 100 Loss 2.6789 Accuracy 0.2707\n",
      "Epoch 19 Loss 2.6777 Accuracy 0.2704\n",
      "Time taken for 1 epoch: 19.41520643234253 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 2.6720 Accuracy 0.2455\n",
      "Epoch 20 Batch 50 Loss 2.6397 Accuracy 0.2745\n",
      "Epoch 20 Batch 100 Loss 2.6175 Accuracy 0.2737\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-4\n",
      "Epoch 20 Loss 2.6173 Accuracy 0.2739\n",
      "Time taken for 1 epoch: 19.32723045349121 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 2.4893 Accuracy 0.2636\n",
      "Epoch 21 Batch 50 Loss 2.5824 Accuracy 0.2781\n",
      "Epoch 21 Batch 100 Loss 2.5594 Accuracy 0.2771\n",
      "Epoch 21 Loss 2.5584 Accuracy 0.2771\n",
      "Time taken for 1 epoch: 18.539202213287354 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 2.5883 Accuracy 0.2776\n",
      "Epoch 22 Batch 50 Loss 2.5229 Accuracy 0.2811\n",
      "Epoch 22 Batch 100 Loss 2.5005 Accuracy 0.2804\n",
      "Epoch 22 Loss 2.5003 Accuracy 0.2805\n",
      "Time taken for 1 epoch: 18.635637760162354 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 2.4426 Accuracy 0.2895\n",
      "Epoch 23 Batch 50 Loss 2.4690 Accuracy 0.2844\n",
      "Epoch 23 Batch 100 Loss 2.4431 Accuracy 0.2828\n",
      "Epoch 23 Loss 2.4425 Accuracy 0.2832\n",
      "Time taken for 1 epoch: 18.488181352615356 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 2.4596 Accuracy 0.2717\n",
      "Epoch 24 Batch 50 Loss 2.4171 Accuracy 0.2859\n",
      "Epoch 24 Batch 100 Loss 2.3914 Accuracy 0.2846\n",
      "Epoch 24 Loss 2.3904 Accuracy 0.2850\n",
      "Time taken for 1 epoch: 18.685598373413086 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 2.3958 Accuracy 0.3262\n",
      "Epoch 25 Batch 50 Loss 2.3593 Accuracy 0.2924\n",
      "Epoch 25 Batch 100 Loss 2.3435 Accuracy 0.2896\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-5\n",
      "Epoch 25 Loss 2.3412 Accuracy 0.2895\n",
      "Time taken for 1 epoch: 18.686834573745728 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 2.3281 Accuracy 0.3060\n",
      "Epoch 26 Batch 50 Loss 2.3100 Accuracy 0.2925\n",
      "Epoch 26 Batch 100 Loss 2.2960 Accuracy 0.2895\n",
      "Epoch 26 Loss 2.2944 Accuracy 0.2895\n",
      "Time taken for 1 epoch: 18.674566984176636 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 2.2720 Accuracy 0.2865\n",
      "Epoch 27 Batch 50 Loss 2.2642 Accuracy 0.2960\n",
      "Epoch 27 Batch 100 Loss 2.2476 Accuracy 0.2952\n",
      "Epoch 27 Loss 2.2478 Accuracy 0.2950\n",
      "Time taken for 1 epoch: 20.758224725723267 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 2.2059 Accuracy 0.3226\n",
      "Epoch 28 Batch 50 Loss 2.2282 Accuracy 0.2941\n",
      "Epoch 28 Batch 100 Loss 2.2064 Accuracy 0.2948\n",
      "Epoch 28 Loss 2.2067 Accuracy 0.2944\n",
      "Time taken for 1 epoch: 21.085672616958618 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 2.1523 Accuracy 0.2841\n",
      "Epoch 29 Batch 50 Loss 2.1790 Accuracy 0.2960\n",
      "Epoch 29 Batch 100 Loss 2.1641 Accuracy 0.2965\n",
      "Epoch 29 Loss 2.1642 Accuracy 0.2970\n",
      "Time taken for 1 epoch: 19.192161798477173 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 2.0914 Accuracy 0.2841\n",
      "Epoch 30 Batch 50 Loss 2.1452 Accuracy 0.2998\n",
      "Epoch 30 Batch 100 Loss 2.1241 Accuracy 0.3002\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-6\n",
      "Epoch 30 Loss 2.1235 Accuracy 0.2998\n",
      "Time taken for 1 epoch: 20.33803677558899 secs\n",
      "\n",
      "Epoch 31 Batch 0 Loss 2.1475 Accuracy 0.2964\n",
      "Epoch 31 Batch 50 Loss 2.1083 Accuracy 0.2997\n",
      "Epoch 31 Batch 100 Loss 2.0876 Accuracy 0.2991\n",
      "Epoch 31 Loss 2.0872 Accuracy 0.2993\n",
      "Time taken for 1 epoch: 20.411208868026733 secs\n",
      "\n",
      "Epoch 32 Batch 0 Loss 2.0554 Accuracy 0.3392\n",
      "Epoch 32 Batch 50 Loss 2.0735 Accuracy 0.3055\n",
      "Epoch 32 Batch 100 Loss 2.0522 Accuracy 0.3045\n",
      "Epoch 32 Loss 2.0523 Accuracy 0.3043\n",
      "Time taken for 1 epoch: 27.018118381500244 secs\n",
      "\n",
      "Epoch 33 Batch 0 Loss 1.9441 Accuracy 0.3355\n",
      "Epoch 33 Batch 50 Loss 2.0421 Accuracy 0.3034\n",
      "Epoch 33 Batch 100 Loss 2.0234 Accuracy 0.3048\n",
      "Epoch 33 Loss 2.0216 Accuracy 0.3045\n",
      "Time taken for 1 epoch: 28.702484130859375 secs\n",
      "\n",
      "Epoch 34 Batch 0 Loss 1.9979 Accuracy 0.2784\n",
      "Epoch 34 Batch 50 Loss 2.0014 Accuracy 0.3079\n",
      "Epoch 34 Batch 100 Loss 1.9857 Accuracy 0.3069\n",
      "Epoch 34 Loss 1.9849 Accuracy 0.3067\n",
      "Time taken for 1 epoch: 22.038177728652954 secs\n",
      "\n",
      "Epoch 35 Batch 0 Loss 2.0077 Accuracy 0.3092\n",
      "Epoch 35 Batch 50 Loss 1.9779 Accuracy 0.3079\n",
      "Epoch 35 Batch 100 Loss 1.9597 Accuracy 0.3076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 35 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-7\n",
      "Epoch 35 Loss 1.9574 Accuracy 0.3086\n",
      "Time taken for 1 epoch: 21.049508333206177 secs\n",
      "\n",
      "Epoch 36 Batch 0 Loss 1.9286 Accuracy 0.3207\n",
      "Epoch 36 Batch 50 Loss 1.9460 Accuracy 0.3101\n",
      "Epoch 36 Batch 100 Loss 1.9281 Accuracy 0.3103\n",
      "Epoch 36 Loss 1.9287 Accuracy 0.3101\n",
      "Time taken for 1 epoch: 19.626209020614624 secs\n",
      "\n",
      "Epoch 37 Batch 0 Loss 1.8071 Accuracy 0.2899\n",
      "Epoch 37 Batch 50 Loss 1.9202 Accuracy 0.3089\n",
      "Epoch 37 Batch 100 Loss 1.9027 Accuracy 0.3097\n",
      "Epoch 37 Loss 1.9024 Accuracy 0.3095\n",
      "Time taken for 1 epoch: 22.376564025878906 secs\n",
      "\n",
      "Epoch 38 Batch 0 Loss 1.8863 Accuracy 0.3254\n",
      "Epoch 38 Batch 50 Loss 1.8967 Accuracy 0.3116\n",
      "Epoch 38 Batch 100 Loss 1.8768 Accuracy 0.3129\n",
      "Epoch 38 Loss 1.8774 Accuracy 0.3128\n",
      "Time taken for 1 epoch: 21.16112995147705 secs\n",
      "\n",
      "Epoch 39 Batch 0 Loss 1.8128 Accuracy 0.3018\n",
      "Epoch 39 Batch 50 Loss 1.8633 Accuracy 0.3157\n",
      "Epoch 39 Batch 100 Loss 1.8471 Accuracy 0.3151\n",
      "Epoch 39 Loss 1.8468 Accuracy 0.3152\n",
      "Time taken for 1 epoch: 21.528167963027954 secs\n",
      "\n",
      "Epoch 40 Batch 0 Loss 1.8168 Accuracy 0.2817\n",
      "Epoch 40 Batch 50 Loss 1.8421 Accuracy 0.3146\n",
      "Epoch 40 Batch 100 Loss 1.8231 Accuracy 0.3141\n",
      "Saving checkpoint for epoch 40 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-8\n",
      "Epoch 40 Loss 1.8215 Accuracy 0.3141\n",
      "Time taken for 1 epoch: 21.22156572341919 secs\n",
      "\n",
      "Epoch 41 Batch 0 Loss 1.8330 Accuracy 0.3039\n",
      "Epoch 41 Batch 50 Loss 1.8206 Accuracy 0.3164\n",
      "Epoch 41 Batch 100 Loss 1.7984 Accuracy 0.3184\n",
      "Epoch 41 Loss 1.7993 Accuracy 0.3176\n",
      "Time taken for 1 epoch: 22.001449584960938 secs\n",
      "\n",
      "Epoch 42 Batch 0 Loss 1.6904 Accuracy 0.2938\n",
      "Epoch 42 Batch 50 Loss 1.7889 Accuracy 0.3198\n",
      "Epoch 42 Batch 100 Loss 1.7703 Accuracy 0.3198\n",
      "Epoch 42 Loss 1.7684 Accuracy 0.3193\n",
      "Time taken for 1 epoch: 23.020848512649536 secs\n",
      "\n",
      "Epoch 43 Batch 0 Loss 1.7267 Accuracy 0.3108\n",
      "Epoch 43 Batch 50 Loss 1.7608 Accuracy 0.3224\n",
      "Epoch 43 Batch 100 Loss 1.7480 Accuracy 0.3198\n",
      "Epoch 43 Loss 1.7471 Accuracy 0.3196\n",
      "Time taken for 1 epoch: 22.47077751159668 secs\n",
      "\n",
      "Epoch 44 Batch 0 Loss 1.7494 Accuracy 0.3162\n",
      "Epoch 44 Batch 50 Loss 1.7372 Accuracy 0.3256\n",
      "Epoch 44 Batch 100 Loss 1.7221 Accuracy 0.3233\n",
      "Epoch 44 Loss 1.7227 Accuracy 0.3228\n",
      "Time taken for 1 epoch: 22.09574580192566 secs\n",
      "\n",
      "Epoch 45 Batch 0 Loss 1.7452 Accuracy 0.3158\n",
      "Epoch 45 Batch 50 Loss 1.7119 Accuracy 0.3233\n",
      "Epoch 45 Batch 100 Loss 1.6964 Accuracy 0.3232\n",
      "Saving checkpoint for epoch 45 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-9\n",
      "Epoch 45 Loss 1.6942 Accuracy 0.3234\n",
      "Time taken for 1 epoch: 19.904141664505005 secs\n",
      "\n",
      "Epoch 46 Batch 0 Loss 1.6324 Accuracy 0.3433\n",
      "Epoch 46 Batch 50 Loss 1.7018 Accuracy 0.3233\n",
      "Epoch 46 Batch 100 Loss 1.6770 Accuracy 0.3245\n",
      "Epoch 46 Loss 1.6770 Accuracy 0.3245\n",
      "Time taken for 1 epoch: 19.59231424331665 secs\n",
      "\n",
      "Epoch 47 Batch 0 Loss 1.7491 Accuracy 0.2866\n",
      "Epoch 47 Batch 50 Loss 1.6724 Accuracy 0.3299\n",
      "Epoch 47 Batch 100 Loss 1.6553 Accuracy 0.3305\n",
      "Epoch 47 Loss 1.6543 Accuracy 0.3304\n",
      "Time taken for 1 epoch: 19.468183994293213 secs\n",
      "\n",
      "Epoch 48 Batch 0 Loss 1.6193 Accuracy 0.3244\n",
      "Epoch 48 Batch 50 Loss 1.6470 Accuracy 0.3294\n",
      "Epoch 48 Batch 100 Loss 1.6313 Accuracy 0.3285\n",
      "Epoch 48 Loss 1.6312 Accuracy 0.3285\n",
      "Time taken for 1 epoch: 19.60358190536499 secs\n",
      "\n",
      "Epoch 49 Batch 0 Loss 1.5622 Accuracy 0.3342\n",
      "Epoch 49 Batch 50 Loss 1.6353 Accuracy 0.3282\n",
      "Epoch 49 Batch 100 Loss 1.6169 Accuracy 0.3289\n",
      "Epoch 49 Loss 1.6154 Accuracy 0.3292\n",
      "Time taken for 1 epoch: 19.700116395950317 secs\n",
      "\n",
      "Epoch 50 Batch 0 Loss 1.5953 Accuracy 0.2981\n",
      "Epoch 50 Batch 50 Loss 1.6150 Accuracy 0.3314\n",
      "Epoch 50 Batch 100 Loss 1.5977 Accuracy 0.3303\n",
      "Saving checkpoint for epoch 50 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-10\n",
      "Epoch 50 Loss 1.5980 Accuracy 0.3304\n",
      "Time taken for 1 epoch: 19.82973289489746 secs\n",
      "\n",
      "Epoch 51 Batch 0 Loss 1.6119 Accuracy 0.3347\n",
      "Epoch 51 Batch 50 Loss 1.5986 Accuracy 0.3349\n",
      "Epoch 51 Batch 100 Loss 1.5862 Accuracy 0.3326\n",
      "Epoch 51 Loss 1.5855 Accuracy 0.3325\n",
      "Time taken for 1 epoch: 19.966489553451538 secs\n",
      "\n",
      "Epoch 52 Batch 0 Loss 1.5973 Accuracy 0.3464\n",
      "Epoch 52 Batch 50 Loss 1.5802 Accuracy 0.3343\n",
      "Epoch 52 Batch 100 Loss 1.5668 Accuracy 0.3341\n",
      "Epoch 52 Loss 1.5660 Accuracy 0.3343\n",
      "Time taken for 1 epoch: 19.611546754837036 secs\n",
      "\n",
      "Epoch 53 Batch 0 Loss 1.6548 Accuracy 0.3186\n",
      "Epoch 53 Batch 50 Loss 1.5702 Accuracy 0.3348\n",
      "Epoch 53 Batch 100 Loss 1.5574 Accuracy 0.3337\n",
      "Epoch 53 Loss 1.5578 Accuracy 0.3328\n",
      "Time taken for 1 epoch: 19.879570722579956 secs\n",
      "\n",
      "Epoch 54 Batch 0 Loss 1.6194 Accuracy 0.3382\n",
      "Epoch 54 Batch 50 Loss 1.5519 Accuracy 0.3374\n",
      "Epoch 54 Batch 100 Loss 1.5344 Accuracy 0.3359\n",
      "Epoch 54 Loss 1.5339 Accuracy 0.3357\n",
      "Time taken for 1 epoch: 24.713441848754883 secs\n",
      "\n",
      "Epoch 55 Batch 0 Loss 1.5537 Accuracy 0.3271\n",
      "Epoch 55 Batch 50 Loss 1.5315 Accuracy 0.3365\n",
      "Epoch 55 Batch 100 Loss 1.5182 Accuracy 0.3367\n",
      "Saving checkpoint for epoch 55 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-11\n",
      "Epoch 55 Loss 1.5198 Accuracy 0.3359\n",
      "Time taken for 1 epoch: 22.61719512939453 secs\n",
      "\n",
      "Epoch 56 Batch 0 Loss 1.5696 Accuracy 0.3258\n",
      "Epoch 56 Batch 50 Loss 1.5350 Accuracy 0.3402\n",
      "Epoch 56 Batch 100 Loss 1.5163 Accuracy 0.3365\n",
      "Epoch 56 Loss 1.5143 Accuracy 0.3364\n",
      "Time taken for 1 epoch: 21.7113299369812 secs\n",
      "\n",
      "Epoch 57 Batch 0 Loss 1.4955 Accuracy 0.3316\n",
      "Epoch 57 Batch 50 Loss 1.5095 Accuracy 0.3402\n",
      "Epoch 57 Batch 100 Loss 1.4952 Accuracy 0.3367\n",
      "Epoch 57 Loss 1.4963 Accuracy 0.3370\n",
      "Time taken for 1 epoch: 21.990220546722412 secs\n",
      "\n",
      "Epoch 58 Batch 0 Loss 1.4953 Accuracy 0.3557\n",
      "Epoch 58 Batch 50 Loss 1.5012 Accuracy 0.3400\n",
      "Epoch 58 Batch 100 Loss 1.4845 Accuracy 0.3398\n",
      "Epoch 58 Loss 1.4849 Accuracy 0.3401\n",
      "Time taken for 1 epoch: 21.484140157699585 secs\n",
      "\n",
      "Epoch 59 Batch 0 Loss 1.5310 Accuracy 0.3364\n",
      "Epoch 59 Batch 50 Loss 1.4903 Accuracy 0.3401\n",
      "Epoch 59 Batch 100 Loss 1.4741 Accuracy 0.3380\n",
      "Epoch 59 Loss 1.4749 Accuracy 0.3381\n",
      "Time taken for 1 epoch: 21.37914252281189 secs\n",
      "\n",
      "Epoch 60 Batch 0 Loss 1.4759 Accuracy 0.3409\n",
      "Epoch 60 Batch 50 Loss 1.4816 Accuracy 0.3414\n",
      "Epoch 60 Batch 100 Loss 1.4648 Accuracy 0.3410\n",
      "Saving checkpoint for epoch 60 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-12\n",
      "Epoch 60 Loss 1.4637 Accuracy 0.3410\n",
      "Time taken for 1 epoch: 23.581963062286377 secs\n",
      "\n",
      "Epoch 61 Batch 0 Loss 1.3607 Accuracy 0.3285\n",
      "Epoch 61 Batch 50 Loss 1.4666 Accuracy 0.3391\n",
      "Epoch 61 Batch 100 Loss 1.4551 Accuracy 0.3392\n",
      "Epoch 61 Loss 1.4559 Accuracy 0.3398\n",
      "Time taken for 1 epoch: 22.63968586921692 secs\n",
      "\n",
      "Epoch 62 Batch 0 Loss 1.4635 Accuracy 0.3051\n",
      "Epoch 62 Batch 50 Loss 1.4498 Accuracy 0.3403\n",
      "Epoch 62 Batch 100 Loss 1.4397 Accuracy 0.3418\n",
      "Epoch 62 Loss 1.4403 Accuracy 0.3421\n",
      "Time taken for 1 epoch: 19.722129344940186 secs\n",
      "\n",
      "Epoch 63 Batch 0 Loss 1.4790 Accuracy 0.3548\n",
      "Epoch 63 Batch 50 Loss 1.4486 Accuracy 0.3424\n",
      "Epoch 63 Batch 100 Loss 1.4366 Accuracy 0.3433\n",
      "Epoch 63 Loss 1.4357 Accuracy 0.3430\n",
      "Time taken for 1 epoch: 19.734100580215454 secs\n",
      "\n",
      "Epoch 64 Batch 0 Loss 1.3794 Accuracy 0.3125\n",
      "Epoch 64 Batch 50 Loss 1.4331 Accuracy 0.3423\n",
      "Epoch 64 Batch 100 Loss 1.4193 Accuracy 0.3422\n",
      "Epoch 64 Loss 1.4184 Accuracy 0.3428\n",
      "Time taken for 1 epoch: 19.701066970825195 secs\n",
      "\n",
      "Epoch 65 Batch 0 Loss 1.3922 Accuracy 0.3608\n",
      "Epoch 65 Batch 50 Loss 1.4267 Accuracy 0.3474\n",
      "Epoch 65 Batch 100 Loss 1.4133 Accuracy 0.3450\n",
      "Saving checkpoint for epoch 65 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-13\n",
      "Epoch 65 Loss 1.4144 Accuracy 0.3445\n",
      "Time taken for 1 epoch: 20.240890502929688 secs\n",
      "\n",
      "Epoch 66 Batch 0 Loss 1.3685 Accuracy 0.3411\n",
      "Epoch 66 Batch 50 Loss 1.4117 Accuracy 0.3447\n",
      "Epoch 66 Batch 100 Loss 1.4000 Accuracy 0.3457\n",
      "Epoch 66 Loss 1.3978 Accuracy 0.3453\n",
      "Time taken for 1 epoch: 19.717613220214844 secs\n",
      "\n",
      "Epoch 67 Batch 0 Loss 1.4171 Accuracy 0.3072\n",
      "Epoch 67 Batch 50 Loss 1.4180 Accuracy 0.3435\n",
      "Epoch 67 Batch 100 Loss 1.4008 Accuracy 0.3438\n",
      "Epoch 67 Loss 1.3999 Accuracy 0.3441\n",
      "Time taken for 1 epoch: 19.557583570480347 secs\n",
      "\n",
      "Epoch 68 Batch 0 Loss 1.3310 Accuracy 0.3653\n",
      "Epoch 68 Batch 50 Loss 1.4060 Accuracy 0.3485\n",
      "Epoch 68 Batch 100 Loss 1.3939 Accuracy 0.3467\n",
      "Epoch 68 Loss 1.3922 Accuracy 0.3465\n",
      "Time taken for 1 epoch: 19.54714274406433 secs\n",
      "\n",
      "Epoch 69 Batch 0 Loss 1.4535 Accuracy 0.3043\n",
      "Epoch 69 Batch 50 Loss 1.3883 Accuracy 0.3489\n",
      "Epoch 69 Batch 100 Loss 1.3751 Accuracy 0.3463\n",
      "Epoch 69 Loss 1.3761 Accuracy 0.3467\n",
      "Time taken for 1 epoch: 19.664090156555176 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 0 Loss 1.3754 Accuracy 0.3261\n",
      "Epoch 70 Batch 50 Loss 1.3845 Accuracy 0.3464\n",
      "Epoch 70 Batch 100 Loss 1.3740 Accuracy 0.3455\n",
      "Saving checkpoint for epoch 70 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-14\n",
      "Epoch 70 Loss 1.3730 Accuracy 0.3461\n",
      "Time taken for 1 epoch: 19.8467013835907 secs\n",
      "\n",
      "Epoch 71 Batch 0 Loss 1.2914 Accuracy 0.3911\n",
      "Epoch 71 Batch 50 Loss 1.3793 Accuracy 0.3490\n",
      "Epoch 71 Batch 100 Loss 1.3627 Accuracy 0.3483\n",
      "Epoch 71 Loss 1.3618 Accuracy 0.3480\n",
      "Time taken for 1 epoch: 20.375503540039062 secs\n",
      "\n",
      "Epoch 72 Batch 0 Loss 1.3316 Accuracy 0.3694\n",
      "Epoch 72 Batch 50 Loss 1.3736 Accuracy 0.3472\n",
      "Epoch 72 Batch 100 Loss 1.3614 Accuracy 0.3465\n",
      "Epoch 72 Loss 1.3619 Accuracy 0.3463\n",
      "Time taken for 1 epoch: 19.838087797164917 secs\n",
      "\n",
      "Epoch 73 Batch 0 Loss 1.3568 Accuracy 0.3507\n",
      "Epoch 73 Batch 50 Loss 1.3602 Accuracy 0.3500\n",
      "Epoch 73 Batch 100 Loss 1.3490 Accuracy 0.3500\n",
      "Epoch 73 Loss 1.3484 Accuracy 0.3500\n",
      "Time taken for 1 epoch: 19.93117928504944 secs\n",
      "\n",
      "Epoch 74 Batch 0 Loss 1.3572 Accuracy 0.3372\n",
      "Epoch 74 Batch 50 Loss 1.3521 Accuracy 0.3534\n",
      "Epoch 74 Batch 100 Loss 1.3395 Accuracy 0.3500\n",
      "Epoch 74 Loss 1.3390 Accuracy 0.3499\n",
      "Time taken for 1 epoch: 20.264663457870483 secs\n",
      "\n",
      "Epoch 75 Batch 0 Loss 1.3516 Accuracy 0.3960\n",
      "Epoch 75 Batch 50 Loss 1.3535 Accuracy 0.3505\n",
      "Epoch 75 Batch 100 Loss 1.3363 Accuracy 0.3485\n",
      "Saving checkpoint for epoch 75 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-15\n",
      "Epoch 75 Loss 1.3366 Accuracy 0.3487\n",
      "Time taken for 1 epoch: 19.85065460205078 secs\n",
      "\n",
      "Epoch 76 Batch 0 Loss 1.3313 Accuracy 0.3525\n",
      "Epoch 76 Batch 50 Loss 1.3510 Accuracy 0.3502\n",
      "Epoch 76 Batch 100 Loss 1.3300 Accuracy 0.3514\n",
      "Epoch 76 Loss 1.3293 Accuracy 0.3515\n",
      "Time taken for 1 epoch: 20.765600204467773 secs\n",
      "\n",
      "Epoch 77 Batch 0 Loss 1.3094 Accuracy 0.3129\n",
      "Epoch 77 Batch 50 Loss 1.3315 Accuracy 0.3542\n",
      "Epoch 77 Batch 100 Loss 1.3208 Accuracy 0.3534\n",
      "Epoch 77 Loss 1.3218 Accuracy 0.3535\n",
      "Time taken for 1 epoch: 19.255093574523926 secs\n",
      "\n",
      "Epoch 78 Batch 0 Loss 1.3182 Accuracy 0.3544\n",
      "Epoch 78 Batch 50 Loss 1.3281 Accuracy 0.3514\n",
      "Epoch 78 Batch 100 Loss 1.3138 Accuracy 0.3501\n",
      "Epoch 78 Loss 1.3136 Accuracy 0.3503\n",
      "Time taken for 1 epoch: 19.71060538291931 secs\n",
      "\n",
      "Epoch 79 Batch 0 Loss 1.3186 Accuracy 0.3602\n",
      "Epoch 79 Batch 50 Loss 1.3291 Accuracy 0.3531\n",
      "Epoch 79 Batch 100 Loss 1.3147 Accuracy 0.3513\n",
      "Epoch 79 Loss 1.3150 Accuracy 0.3519\n",
      "Time taken for 1 epoch: 19.294681787490845 secs\n",
      "\n",
      "Epoch 80 Batch 0 Loss 1.3017 Accuracy 0.3104\n",
      "Epoch 80 Batch 50 Loss 1.3151 Accuracy 0.3554\n",
      "Epoch 80 Batch 100 Loss 1.3008 Accuracy 0.3535\n",
      "Saving checkpoint for epoch 80 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-16\n",
      "Epoch 80 Loss 1.3007 Accuracy 0.3529\n",
      "Time taken for 1 epoch: 19.785135984420776 secs\n",
      "\n",
      "Epoch 81 Batch 0 Loss 1.3312 Accuracy 0.3475\n",
      "Epoch 81 Batch 50 Loss 1.3195 Accuracy 0.3528\n",
      "Epoch 81 Batch 100 Loss 1.3035 Accuracy 0.3537\n",
      "Epoch 81 Loss 1.3035 Accuracy 0.3544\n",
      "Time taken for 1 epoch: 22.158150672912598 secs\n",
      "\n",
      "Epoch 82 Batch 0 Loss 1.2702 Accuracy 0.3520\n",
      "Epoch 82 Batch 50 Loss 1.3110 Accuracy 0.3554\n",
      "Epoch 82 Batch 100 Loss 1.2972 Accuracy 0.3553\n",
      "Epoch 82 Loss 1.2974 Accuracy 0.3549\n",
      "Time taken for 1 epoch: 22.634587287902832 secs\n",
      "\n",
      "Epoch 83 Batch 0 Loss 1.2661 Accuracy 0.3433\n",
      "Epoch 83 Batch 50 Loss 1.3017 Accuracy 0.3535\n",
      "Epoch 83 Batch 100 Loss 1.2876 Accuracy 0.3537\n",
      "Epoch 83 Loss 1.2858 Accuracy 0.3532\n",
      "Time taken for 1 epoch: 19.95818853378296 secs\n",
      "\n",
      "Epoch 84 Batch 0 Loss 1.2393 Accuracy 0.3392\n",
      "Epoch 84 Batch 50 Loss 1.2966 Accuracy 0.3585\n",
      "Epoch 84 Batch 100 Loss 1.2875 Accuracy 0.3566\n",
      "Epoch 84 Loss 1.2873 Accuracy 0.3554\n",
      "Time taken for 1 epoch: 19.66315507888794 secs\n",
      "\n",
      "Epoch 85 Batch 0 Loss 1.3332 Accuracy 0.3525\n",
      "Epoch 85 Batch 50 Loss 1.2952 Accuracy 0.3543\n",
      "Epoch 85 Batch 100 Loss 1.2809 Accuracy 0.3543\n",
      "Saving checkpoint for epoch 85 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-17\n",
      "Epoch 85 Loss 1.2803 Accuracy 0.3541\n",
      "Time taken for 1 epoch: 19.84771418571472 secs\n",
      "\n",
      "Epoch 86 Batch 0 Loss 1.2997 Accuracy 0.3948\n",
      "Epoch 86 Batch 50 Loss 1.2878 Accuracy 0.3599\n",
      "Epoch 86 Batch 100 Loss 1.2750 Accuracy 0.3587\n",
      "Epoch 86 Loss 1.2741 Accuracy 0.3588\n",
      "Time taken for 1 epoch: 20.35788130760193 secs\n",
      "\n",
      "Epoch 87 Batch 0 Loss 1.2173 Accuracy 0.3602\n",
      "Epoch 87 Batch 50 Loss 1.2848 Accuracy 0.3563\n",
      "Epoch 87 Batch 100 Loss 1.2683 Accuracy 0.3555\n",
      "Epoch 87 Loss 1.2661 Accuracy 0.3556\n",
      "Time taken for 1 epoch: 19.704662561416626 secs\n",
      "\n",
      "Epoch 88 Batch 0 Loss 1.2364 Accuracy 0.3302\n",
      "Epoch 88 Batch 50 Loss 1.2796 Accuracy 0.3559\n",
      "Epoch 88 Batch 100 Loss 1.2668 Accuracy 0.3552\n",
      "Epoch 88 Loss 1.2664 Accuracy 0.3557\n",
      "Time taken for 1 epoch: 19.698606729507446 secs\n",
      "\n",
      "Epoch 89 Batch 0 Loss 1.1999 Accuracy 0.3265\n",
      "Epoch 89 Batch 50 Loss 1.2732 Accuracy 0.3607\n",
      "Epoch 89 Batch 100 Loss 1.2620 Accuracy 0.3562\n",
      "Epoch 89 Loss 1.2602 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 19.69054412841797 secs\n",
      "\n",
      "Epoch 90 Batch 0 Loss 1.2710 Accuracy 0.3542\n",
      "Epoch 90 Batch 50 Loss 1.2678 Accuracy 0.3557\n",
      "Epoch 90 Batch 100 Loss 1.2506 Accuracy 0.3584\n",
      "Saving checkpoint for epoch 90 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-18\n",
      "Epoch 90 Loss 1.2518 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 19.923101902008057 secs\n",
      "\n",
      "Epoch 91 Batch 0 Loss 1.1250 Accuracy 0.3809\n",
      "Epoch 91 Batch 50 Loss 1.2755 Accuracy 0.3558\n",
      "Epoch 91 Batch 100 Loss 1.2542 Accuracy 0.3587\n",
      "Epoch 91 Loss 1.2538 Accuracy 0.3586\n",
      "Time taken for 1 epoch: 19.54663586616516 secs\n",
      "\n",
      "Epoch 92 Batch 0 Loss 1.2304 Accuracy 0.3433\n",
      "Epoch 92 Batch 50 Loss 1.2527 Accuracy 0.3592\n",
      "Epoch 92 Batch 100 Loss 1.2468 Accuracy 0.3566\n",
      "Epoch 92 Loss 1.2462 Accuracy 0.3566\n",
      "Time taken for 1 epoch: 19.88921570777893 secs\n",
      "\n",
      "Epoch 93 Batch 0 Loss 1.3419 Accuracy 0.3594\n",
      "Epoch 93 Batch 50 Loss 1.2592 Accuracy 0.3605\n",
      "Epoch 93 Batch 100 Loss 1.2453 Accuracy 0.3582\n",
      "Epoch 93 Loss 1.2448 Accuracy 0.3585\n",
      "Time taken for 1 epoch: 19.687584161758423 secs\n",
      "\n",
      "Epoch 94 Batch 0 Loss 1.2096 Accuracy 0.3681\n",
      "Epoch 94 Batch 50 Loss 1.2605 Accuracy 0.3581\n",
      "Epoch 94 Batch 100 Loss 1.2430 Accuracy 0.3591\n",
      "Epoch 94 Loss 1.2421 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 19.57812213897705 secs\n",
      "\n",
      "Epoch 95 Batch 0 Loss 1.2670 Accuracy 0.3302\n",
      "Epoch 95 Batch 50 Loss 1.2519 Accuracy 0.3605\n",
      "Epoch 95 Batch 100 Loss 1.2340 Accuracy 0.3603\n",
      "Saving checkpoint for epoch 95 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-19\n",
      "Epoch 95 Loss 1.2337 Accuracy 0.3596\n",
      "Time taken for 1 epoch: 20.490225076675415 secs\n",
      "\n",
      "Epoch 96 Batch 0 Loss 1.2138 Accuracy 0.3310\n",
      "Epoch 96 Batch 50 Loss 1.2559 Accuracy 0.3611\n",
      "Epoch 96 Batch 100 Loss 1.2345 Accuracy 0.3590\n",
      "Epoch 96 Loss 1.2343 Accuracy 0.3598\n",
      "Time taken for 1 epoch: 20.559048175811768 secs\n",
      "\n",
      "Epoch 97 Batch 0 Loss 1.1066 Accuracy 0.3659\n",
      "Epoch 97 Batch 50 Loss 1.2439 Accuracy 0.3608\n",
      "Epoch 97 Batch 100 Loss 1.2304 Accuracy 0.3612\n",
      "Epoch 97 Loss 1.2304 Accuracy 0.3608\n",
      "Time taken for 1 epoch: 19.717705488204956 secs\n",
      "\n",
      "Epoch 98 Batch 0 Loss 1.2245 Accuracy 0.3472\n",
      "Epoch 98 Batch 50 Loss 1.2336 Accuracy 0.3591\n",
      "Epoch 98 Batch 100 Loss 1.2232 Accuracy 0.3577\n",
      "Epoch 98 Loss 1.2225 Accuracy 0.3582\n",
      "Time taken for 1 epoch: 19.969600200653076 secs\n",
      "\n",
      "Epoch 99 Batch 0 Loss 1.2300 Accuracy 0.3368\n",
      "Epoch 99 Batch 50 Loss 1.2300 Accuracy 0.3617\n",
      "Epoch 99 Batch 100 Loss 1.2164 Accuracy 0.3600\n",
      "Epoch 99 Loss 1.2160 Accuracy 0.3599\n",
      "Time taken for 1 epoch: 19.141549587249756 secs\n",
      "\n",
      "Epoch 100 Batch 0 Loss 1.2080 Accuracy 0.3326\n",
      "Epoch 100 Batch 50 Loss 1.2366 Accuracy 0.3632\n",
      "Epoch 100 Batch 100 Loss 1.2187 Accuracy 0.3634\n",
      "Saving checkpoint for epoch 100 at ./checkpoints/Final_Trans_EngYue_Char_2\\ckpt-20\n",
      "Epoch 100 Loss 1.2173 Accuracy 0.3630\n",
      "Time taken for 1 epoch: 19.219812393188477 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  # Save output to TensorBoard\n",
    "  with summary_writer.as_default():\n",
    "    tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch + 1)\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy.result(), step=epoch + 1)\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6APsFrgImLW"
   },
   "source": [
    "The following steps are used for evaluation:\n",
    "\n",
    "* Encode the input sentence using the `input_tokenizer`. Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "* The decoder input is the `start token == target_tokenizer.vocab_size`.\n",
    "* Calculate the padding masks and the look ahead masks.\n",
    "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
    "* Select the last word and calculate the argmax of that.\n",
    "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "* In this approach, the decoder predicts the next word based on the previous words it predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [input_tokenizer.vocab_size]\n",
    "  end_token = [input_tokenizer.vocab_size + 1]\n",
    "  \n",
    "  inp_sentence = start_token + input_tokenizer.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  decoder_input = [target_tokenizer.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == target_tokenizer.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese font in matplotlib\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import wget\n",
    "# !wget -qO taipei_sans_tc_beta.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n",
    "# !mv taipei_sans_tc_beta.ttf /usr/local/lib/python3.6/dist-packages/matplotlib//mpl-data/fonts/ttf\n",
    "# chinese = FontProperties(fname=r'/usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf/taipei_sans_tc_beta.ttf')\n",
    "if not os.path.isfile('taipei_sans_tc_beta.ttf'):\n",
    "    wget.download('https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download', 'taipei_sans_tc_beta.ttf')\n",
    "chinese = FontProperties(fname=r'taipei_sans_tc_beta.ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "CN-BV43FMBej"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = input_tokenizer.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    # show Chinese character\n",
    "    fontdict = {\"fontproperties\": chinese}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[input_tokenizer.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([target_tokenizer.decode([i]) for i in result \n",
    "                        if i < target_tokenizer.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = target_tokenizer.decode([i for i in result \n",
    "                                            if i < target_tokenizer.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "gZwVWTohOv4_",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which has to do with suicide\n",
      "咁 當 然 啦 自 殺 本 身 唔 係 一 種 病 \n",
      "\n",
      "Input: which has to do with suicide\n",
      "Predicted translation: 就 係 一 個 穩 定\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "row = df_test.sample()\n",
    "inp = row[inp_lang].values[0]\n",
    "tar = row[tar_lang].values[0]\n",
    "print(inp)\n",
    "print(tar, '\\n')\n",
    "\n",
    "translate(inp, plot='decoder_layer1_block1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_2 (Encoder)          multiple                  274784    \n",
      "_________________________________________________________________\n",
      "decoder_2 (Decoder)          multiple                  140768    \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            multiple                  110121    \n",
      "=================================================================\n",
      "Total params: 525,673\n",
      "Trainable params: 525,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateTest(sentence):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  sentence = input_tokenizer.encode(sentence)\n",
    "  sentence = ' '.join([input_tokenizer.decode([i]) for i in sentence])\n",
    "  predicted_sentence = target_tokenizer.decode([i for i in result \n",
    "                                            if i < target_tokenizer.vocab_size])  \n",
    "\n",
    "#   print('Input: {}'.format(sentence))\n",
    "#   print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  return sentence, predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50 / 1696 in 39.496957778930664 s\n",
      "Progress: 100 / 1696 in 40.42063331604004 s\n",
      "Progress: 150 / 1696 in 38.87531495094299 s\n",
      "Progress: 200 / 1696 in 40.27986478805542 s\n",
      "Progress: 250 / 1696 in 37.76585817337036 s\n",
      "Progress: 300 / 1696 in 47.19782114028931 s\n",
      "Progress: 350 / 1696 in 50.165170192718506 s\n",
      "Progress: 400 / 1696 in 46.29144263267517 s\n",
      "Progress: 450 / 1696 in 48.7556848526001 s\n",
      "Progress: 500 / 1696 in 47.88527059555054 s\n",
      "Progress: 550 / 1696 in 76.94551539421082 s\n",
      "Progress: 600 / 1696 in 54.782411336898804 s\n",
      "Progress: 650 / 1696 in 76.17723488807678 s\n",
      "Progress: 700 / 1696 in 72.93858337402344 s\n",
      "Progress: 750 / 1696 in 64.55140686035156 s\n",
      "Progress: 800 / 1696 in 66.35352993011475 s\n",
      "Progress: 850 / 1696 in 81.75115036964417 s\n",
      "Progress: 900 / 1696 in 87.18348383903503 s\n",
      "Progress: 950 / 1696 in 65.7270576953888 s\n",
      "Progress: 1000 / 1696 in 70.54507875442505 s\n",
      "Progress: 1050 / 1696 in 63.47757363319397 s\n",
      "Progress: 1100 / 1696 in 46.046594858169556 s\n",
      "Progress: 1150 / 1696 in 51.732277393341064 s\n",
      "Progress: 1200 / 1696 in 54.358447551727295 s\n",
      "Progress: 1250 / 1696 in 63.08191967010498 s\n",
      "Progress: 1300 / 1696 in 58.77847385406494 s\n",
      "Progress: 1350 / 1696 in 57.026915311813354 s\n",
      "Progress: 1400 / 1696 in 59.72970104217529 s\n",
      "Progress: 1450 / 1696 in 61.81723880767822 s\n",
      "Progress: 1500 / 1696 in 67.86227750778198 s\n",
      "Progress: 1550 / 1696 in 70.05924129486084 s\n",
      "Progress: 1600 / 1696 in 77.77858233451843 s\n",
      "Progress: 1650 / 1696 in 114.95398712158203 s\n",
      "\n",
      "ToTal: 1696 / 1696 in 2065.570368528366 s\n"
     ]
    }
   ],
   "source": [
    "TotalTime = time.time()\n",
    "start = time.time()\n",
    "\n",
    "ori = []\n",
    "ref = []\n",
    "can = []\n",
    "num_test = 0\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    inp = row[inp_lang]\n",
    "    tar = row[tar_lang]\n",
    "    num_test += 1\n",
    "    o, pre = translateTest(inp)\n",
    "    ori.append(o)\n",
    "    ref.append(tar)\n",
    "    if YueChar:\n",
    "        can.append(spliteKeyWord(pre))\n",
    "    else:\n",
    "        can.append(pre)\n",
    "    if num_test % 50 == 0:\n",
    "        print(f'Progress: {num_test} / {len(df_test)} in {time.time()-start} s')\n",
    "        start = time.time()\n",
    "        \n",
    "print(f'\\nToTal: {num_test} / {len(df_test)} in {time.time()-TotalTime} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We  always  over esti mate   the  change  that  will  occu r\n",
      "我 哋 永 遠 都 高 估 咗\n",
      "但 係 事 情 況 會 變 得\n",
      "BLEU: 20.060960272501838\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import random\n",
    "ran = random.randint(1, len(ref))\n",
    "print(ori[ran])\n",
    "print(ref[ran])\n",
    "print(can[ran])\n",
    "\n",
    "smoothie = SmoothingFunction().method4\n",
    "print('BLEU:', sentence_bleu(ref[ran], can[ran], smoothing_function=smoothie)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-s: 40.06817192598113\n",
      "BLEU-c: 3.2325860319198028\n"
     ]
    }
   ],
   "source": [
    "# Sentence-based and average score\n",
    "score = 0\n",
    "for i in range(len(ref)):\n",
    "    r = [ref[i].split()]\n",
    "    c = can[i].split()\n",
    "    score += sentence_bleu(r, c, smoothing_function=smoothie)*100\n",
    "print('BLEU-s:', score/len(ref))\n",
    "\n",
    "# Corpus based, summing all nominator and denominator before division\n",
    "r = [[r.split()] for r in ref]\n",
    "c = [c.split() for c in can]\n",
    "score = corpus_bleu(r, c, smoothing_function=smoothie)*100\n",
    "print('BLEU-c:', score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transformer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
