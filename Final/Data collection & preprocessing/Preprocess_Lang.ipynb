{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocess_Lang.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbJiHd2MKJGz",
        "outputId": "7ea67127-2282-4223-d653-262e7693ee7f"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.upload() \n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "!pip install --upgrade pycantonese\n",
        "import pycantonese as pc\n",
        "from pycantonese.word_segmentation import Segmenter\n",
        "\n",
        "all_txt = glob.glob(os.getcwd() + \"/*.txt\")\n",
        "if len(all_txt) > 0:\n",
        "  corpus = []\n",
        "  for txt in all_txt:\n",
        "    f = open(txt, 'r')\n",
        "    corpus.extend([x for x in f.read().strip().splitlines() if x])\n",
        "    f.close()\n",
        "  corpus_yue = corpus[::2]\n",
        "  corpus_eng = corpus[1::2]\n",
        "  df_txt = pd.DataFrame({'zh': corpus_yue, 'en': corpus_eng})\n",
        "  # df_txt.to_csv('Netflix.csv', sep='\\t', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pycantonese in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wordseg==0.0.2 in /usr/local/lib/python3.6/dist-packages (from pycantonese) (0.0.2)\n",
            "Requirement already satisfied, skipping upgrade: pylangacq<1.0.0,>=0.12.0 in /usr/local/lib/python3.6/dist-packages (from pycantonese) (0.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-f_ERaRKUyk"
      },
      "source": [
        "all_csv = glob.glob(os.getcwd() + \"/*.csv\")  \n",
        " \n",
        "df_from_each_file = (pd.read_csv(f,sep='\\t',encoding='utf-8', index_col=0) for f in all_csv)\n",
        "df = pd.concat(df_from_each_file, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMW5xFwIKXBF"
      },
      "source": [
        "# Unify the character to traditional\n",
        "!wget -qnc https://raw.githubusercontent.com/skydark/nstools/master/zhtools/zh_wiki.py https://raw.githubusercontent.com/skydark/nstools/master/zhtools/langconv.py\n",
        "from langconv import *\n",
        "for file in glob.glob(os.getcwd() + \"/*.py\"):\n",
        "  os.remove(file)\n",
        "def ConvTrad(x):\n",
        "  # !pip install opencc\n",
        "  # import opencc\n",
        "  # converter = opencc.OpenCC('s2hk.json')\n",
        "  return Converter('zh-hant').convert(x)\n",
        " \n",
        "# segment Cantonese sentences\n",
        "segmenter = Segmenter(\n",
        "    allow = {'甘乃迪', '坦帕', '塞拉里昂', '唔淨至', '宗教', '儀式', '上漲', '功夫', '卑牌', '關註', \"系咪\", '就系', '我地', '你地', '佢地', '距地', '呢地', '呢到', '帶嚟'},\n",
        "    disallow = {'系呢', '係呢', \"喺呢\", '呢個係'}\n",
        ")\n",
        "def CantoSeg(x):\n",
        "  return ' '.join(pc.segment(x, cls=segmenter))\n",
        " \n",
        "# replace unuified words to HK version and unify variants into single form\n",
        "def haai5haai2Conv(x):\n",
        "  if all(h in x.split(' ') for h in ['系', '係']):\n",
        "    x = ' '.join(['喺' if len(x) == 1 and x == '係' else x for x in x.split(' ')])\n",
        "    x = ' '.join(['係' if len(x) == 1 and x == '系' else x for x in x.split(' ')])\n",
        "  return x\n",
        "\n",
        "singleReplaceSeq = {\n",
        "    \"系\": \"係\", \n",
        "    \"里\": \"裏\", \n",
        "    '距': '佢',\n",
        "    '黎': '呢', \n",
        "    '果': '嗰', \n",
        "    'D': '啲',\n",
        "    '卑': '俾'\n",
        "}\n",
        "def singleReplace(x):\n",
        "  return ' '.join([singleReplaceSeq[x] if len(x) == 1 and x in singleReplaceSeq.keys() else x for x in x.split(' ')])\n",
        "\n",
        "combo = [f + ' ' + s \n",
        "         for f in ['呢', '嗰', '一'] \n",
        "         for s in ['陣', '啲', '個', '輯', '份', '間', '地']]\n",
        "def combineSequence(x):\n",
        "  for c in combo:\n",
        "    if c in x:\n",
        "      x = x.replace(c, c[::2])\n",
        "  return x\n",
        "\n",
        "\n",
        "Replacement = {\n",
        "    '噶': '嘅',\n",
        "    '裡': '裏',\n",
        "    '哩': '呢',\n",
        "    '咯': '囉',\n",
        "    '佐': '咗',\n",
        "    '姖': '佢',\n",
        "    '系咪': '係咪',\n",
        "    '就系': '就係',\n",
        "    '即系': '即係',\n",
        "    '我地': '我哋',\n",
        "    '你地': '你哋',\n",
        "    '距地': '佢哋',\n",
        "    '呢地': '呢啲',\n",
        "    '嗰地': '嗰啲',\n",
        "    '呢到': '呢度',\n",
        "    '卑牌': '啤牌',\n",
        "    '關註': '關注',\n",
        "    '唔淨至': '唔淨止'\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "zXYjy-HkKmlh",
        "outputId": "e4c205d8-6e48-4e7e-9c2a-30aa76804c78"
      },
      "source": [
        "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "df = df.rename(columns={'zh': 'yue', 'en': 'eng'})\n",
        "\n",
        "df['yue'] = df['yue'].apply(lambda x: ConvTrad(x))\n",
        "df['yue'] = df['yue'].apply(lambda x: CantoSeg(x))\n",
        "df['yue'] = df['yue'].apply(lambda x: haai5haai2Conv(x))\n",
        "df['yue'] = df['yue'].apply(lambda x: singleReplace(x))\n",
        "df['yue'] = df['yue'].apply(lambda x: combineSequence(x))\n",
        "df['yue'] = df['yue'].replace(Replacement, regex=True)\n",
        "\n",
        "# Remove all punctuation and extra space\n",
        "for column in df:\n",
        "  df[column] = df[column].str.replace(r'[^\\w\\s]+', ' ')\n",
        "  df[column] = df[column].str.replace(r' +', ' ')\n",
        "  df[column] = df[column].str.strip()\n",
        " \n",
        "# Let the tokenizer perform segment for Cantonese\n",
        "# df['yue'] = df['yue'].str.replace(r' ', '')\n",
        "df.dropna()\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(f'Data size: {len(df)}')\n",
        "df.head()\n",
        "\n",
        "# from pprint import *\n",
        "# corpus = pc.hkcancor()\n",
        "# pprint(corpus.search(character='難用'))\n",
        "# df[df['yue'].str.contains(' ')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size: 9812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>yue</th>\n",
              "      <th>eng</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>唔覺 得 好 可笑 咩 我哋 製造 出 時速 可以 達到 130 英里 嘅 車 然後 以 1...</td>\n",
              "      <td>Isn t it absurd that we created cars that can ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>因為 佢地 要 瞭解 我 嘅 行動</td>\n",
              "      <td>because they want to know about my business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>聚合 在 一齊 之外 無 其他 用途</td>\n",
              "      <td>like the nerves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>三 個 細路 就係 o 係 呢度 俾 人 抓 左</td>\n",
              "      <td>And that s where the three kids got arrested</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>呢度 係 另一個 例子</td>\n",
              "      <td>So here s another example</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 yue                                                eng\n",
              "0  唔覺 得 好 可笑 咩 我哋 製造 出 時速 可以 達到 130 英里 嘅 車 然後 以 1...  Isn t it absurd that we created cars that can ...\n",
              "1                                  因為 佢地 要 瞭解 我 嘅 行動        because they want to know about my business\n",
              "2                                 聚合 在 一齊 之外 無 其他 用途                                    like the nerves\n",
              "3                           三 個 細路 就係 o 係 呢度 俾 人 抓 左       And that s where the three kids got arrested\n",
              "4                                        呢度 係 另一個 例子                          So here s another example"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNXcBD4nypy3",
        "outputId": "7c649c95-27a4-40f8-ab05-b64945cb5366"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2)\n",
        "train, test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                    yue                                                eng\n",
              " 551   唔準 掂 同 食 醃菜 唔準 坐 梳化 或者 屋企人 嘅 床 上 每次 經期 完 咗 要 洗...  I was not allowed to touch or eat pickles I wa...\n",
              " 902                                        佢地 扮 怪 面 嚇 人                       They were making scary faces\n",
              " 624                       唔會 搞到 我哋 變得 邪惡 女人型 變成 自由黨 人 咩                turn us into godless sissy liberals\n",
              " 4636                              呢個 模式 可以 清晰 令 您 瞭解 佢哋         So it spells those out in very clean terms\n",
              " 4635                                          幾多 萬 億 掌聲                        How many trillions Applause\n",
              " ...                                                 ...                                                ...\n",
              " 5549                                  此 事件 因此 亦 被 不斷 調查                  and the investigation is going on\n",
              " 9422                            我 過去 係 素食主義 者 唔 飲酒 唔食 煙      I was a vegetarian I was sober I didn t smoke\n",
              " 6290  所以 我 開始 諗 如果 每個人 都 好似 婦科醫生 咁 瞭解 月經 嘅話 會 點 唔係 會...  So I began to think Well what if everybody kne...\n",
              " 6788                                        污染 戰爭 成本 上升                     pollution war and rising costs\n",
              " 2558  我哋 嘅 可持續發展 由 以前 做下 都 幾 唔錯 到家 下 必須 做 做 係 好嘅 同埋 ...  So we ve gone from sustainability being a nice...\n",
              " \n",
              " [7849 rows x 2 columns],\n",
              "                                                     yue                                                eng\n",
              " 5450                                             我 相信 主                             I believe the almighty\n",
              " 5661                                好耐 以嚟 有 發展 紊亂 嘅 小朋友  For too long now children with developmental d...\n",
              " 9601                                     一般 會 遇到 兩 種 反應                      I have two kinds of reactions\n",
              " 5000  但 再 諗下 嗰位 官員 未必 係 唯一 睇小 女性 嘅人 呢種 偏見 不論 係咪 特登 係...  But think about this The IMF official is hardl...\n",
              " 6073                                   佢 將 呢個 病毒 傳 畀 BB                   She passes that virus on to baby\n",
              " ...                                                 ...                                                ...\n",
              " 1849                                 我 嘅 影 會 出現 喺 光線 之下            my shadow would be brought to the light\n",
              " 3926                                         身 為 一個 哲學家                           So the philosopher in me\n",
              " 6367  我 係 廚師 同時 負責 制定 食品 政策 我 嘅 屋企 有好多 係 老師 我 家姐 喺 芝...  I am a chef and a food policy guy but I come f...\n",
              " 1292                                       以 我 為例 唔係 講笑                      I for one and I m not kidding\n",
              " 7778                                             係 交通 上                                         in traffic\n",
              " \n",
              " [1963 rows x 2 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12jbiehkLCKK"
      },
      "source": [
        "train.to_csv('train.csv', sep='\\t', index=False, encoding='utf-8')\n",
        "test.to_csv('test.csv', sep='\\t', index=False, encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}